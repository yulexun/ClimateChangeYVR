---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - Lexun Yu
thanks: "Code and data are available at: [https://github.com/yulexun/ClimateChangeYVR](https://github.com/yulexun/ClimateChangeYVR)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(here)
library(arrow)
library(corrplot)
library(knitr)
library(kableExtra)
library(car)
library(modelsummary)

raw_data_climate <- read_csv(here("data/01-raw_data/climateyvr.csv"))
raw_data_ahccd <- read_csv(here("data/01-raw_data/ahccdyvr.csv"))
analysis_data <- read_parquet(here("data/02-analysis_data/cleaned_data.parquet"))
train_data <- read_parquet(here("data/02-analysis_data/train_data.parquet"))
test_data <- read_parquet(here("data/02-analysis_data/test_data.parquet"))
m1 <- readRDS(here("models/m1.rds"))
m4 <- readRDS(here("models/m4.rds"))
glm <- readRDS(here("models/glm_poly.rds"))
brm <- readRDS(here("models/brm.rds"))
glm_log <- readRDS(here("models/glm_log.rds"))
```

```{r}
# Calculate diagnostic measures
glm_model <- glm
# Assuming `glm_model` is your fitted model

# 1. Linearity: Residuals vs Fitted Plot
plot(glm_model, which = 1, main = "Linearity Check: Residuals vs Fitted")
plot(glm_log, which = 1, main = "Linearity Check: Residuals vs Fitted")

# Look for a random scatter of points. Patterns indicate non-linearity.

# 2. Homoscedasticity: Scale-Location Plot
plot(glm_model, which = 3, main = "Homoscedasticity Check: Scale-Location")
plot(glm_log, which = 3, main = "Homoscedasticity Check: Scale-Location")
# Points should be evenly spread. A funnel shape indicates heteroscedasticity.

# 3. Normality of Residuals: Q-Q Plot
plot(glm_model, which = 2, main = "Normality Check: Q-Q Plot")
plot(glm_log, which = 2, main = "Normality Check: Q-Q Plot")

# Points should lie approximately along the diagonal line.

# 4. Residual Histogram: Another Normality Check
residuals <- residuals(glm_model)
hist(residuals, main = "Histogram of Residuals", xlab = "Residuals")
residuals <- residuals(glm_log)
hist(residuals, main = "Histogram of Residuals", xlab = "Residuals")

# Check for symmetry. A skewed histogram suggests non-normal residuals.

# 5. Multicollinearity: Variance Inflation Factor (VIF)
vif_values <- vif(glm_model)
print(vif_values)
vif_values <- vif(glm_log)
print(vif_values)
# VIF > 5 indicates high multicollinearity. Consider removing highly correlated predictors.

# 6. Cook's Distance: Influence of Observations
cooksd <- cooks.distance(glm_model)
plot(cooksd, main = "Cook's Distance", type = "h")
abline(h = 4 / nrow(model.frame(glm_model)), col = "red", lty = 2)

cooksd <- cooks.distance(glm_log)
plot(cooksd, main = "Cook's Distance", type = "h")
abline(h = 4 / nrow(model.frame(glm_log)), col = "red", lty = 2)
# Points above the red line are highly influential.

# 7. Leverage: Identify High Leverage Points
leverage <- hatvalues(glm_model)
plot(leverage, main = "Leverage Check", type = "h")
abline(h = 2 * mean(leverage), col = "red", lty = 2)

leverage <- hatvalues(glm_log)
plot(leverage, main = "Leverage Check", type = "h")
abline(h = 2 * mean(leverage), col = "red", lty = 2)
# Points above the red line have high leverage.


AIC(glm_model)
AIC(glm_log)
BIC(glm_model)
BIC(glm_log)

```

# Introduction

Climate change is a global challenges today. Patterns such as rising temperatures, shifting weather systems, and increased frequency of severe weather events. In 2021, floods swept through streets in Japanese cities, displacing millions, while extreme heat fueled wildfires in Siberia [@greenpeace_east_asia_5_2021]. Climate change impacts human health, ecosystems, food security, water supplies, and economic stability. Understanding the factors driving temperature changes is necessary for designing effective mitigation strategies. This requires examining the various contributors to temperature variations.

Some scholars have examined the changing climate. @xu_melting_2009 analyze the effects of rising temperatures in the Himalayas, highlighting increased frequency and duration of extreme events and shifts in ecosystems. These changes pose challenges to water supply, agriculture, and human populations. @visser_eliminating_2021 investigates the relationship between precipitation and temperature using data from the Australian Bureau of Meteorology. Visser's regression model indicates that average precipitation intensities increase with temperature, suggesting more intense rainfall in a warmer climate. The role of sea level pressure is also significant. @wills_systematic_2022 note that observed trends in sea level pressure have intensified warming in the Indo-Pacific Warm Pool and caused slight cooling in the eastern equatorial Pacific. However, as @zhang_economic_2017 argue, much of the research has focused on temperature and precipitation. @zhang_economic_2017 expands on this by incorporating additional predictors—relative humidity and wind speed—and concludes, using data from the Ministry of Agriculture of China, that these variables are important in understanding climate dynamics. 

Temperatures significantly impact airport operations. Rising temperatures significantly affect aircraft performance, potentially leading to take-off weight restrictions and the need for longer runways. This directly impacts airport capacity and operations [@coffel_climate_2015]. Temperature forecast models vary in different locations, and different regions have unique climate characteristics that models may not fully capture [@american_meteorological_society_weather_nodate]. 

This research paper aims to identify the factors influencing temperature at Vancouver International Airport and build a model for temperature prediction with the data obtained from @canadian_centre_for_climate_services_adjusted_2022 and @meteorological_service_of_canada_past_2023. Located on the west coast of Richmond, the airport sits on Sea Island, surrounded by water. As a transportation hub for passengers and freight, it is important to assess the location's safety in a warming climate.


Estimand paragraph

Results paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

The data gathering and analysis is done in R [@citeR] with the following packages: knitr [@knitr], tidyverse [@tidyverse], ggplot2 [@ggplot2], dplyr [@dplyr], arrow [@arrow], here [@here], and lubridate [@lubridate].

# Data {#sec-data}

## Measurement

The measurement of Canadian weather data involves a network of weather stations and data collection methods managed by Environment and Climate Change Canada (ECCC). These stations continuously measure meteorological parameters such as temperature, precipitation, wind speed, and pressure [@meteorological_service_of_canada_past_2023]. 

According to the glossary published by @meteorological_service_of_canada_past_2023, Each day, measurement of temperature, rain, snow, precipitation, and gust speed are recorded. The wind and gust speed is measured in km/h with anemometer dials at a standard height of 10 meters above the ground. Rain and precipitation are measured in millimeter using the standard Canadian rain guage, a cylindrical container 40 cm high and 11.3 cm in diameter. Snow is measured in centimeters at several points that appear representative of the immediate area and then averaged. These raw data are combined to one entry and added to the historical climate database with a generated climate id and the station's location and id. Each row also have month and year of the data measured.

For climate research, including climate change studies, @environment_and_climate_change_canada_adjusted_2021 has developed the Adjusted and Homogenized Canadian Climate Data (AHCCD) dataset. This dataset undergoes rigorous quality control and homogenization processes to address non-climatic factors that can affect long-term data consistency, such as station relocations or changes in instrumentation. The AHCCD ensures that observed trends reflect actual climate changes rather than artificial shifts in the data. In the AHCCD dataset, the precipitation, rain, pressure, snow and wind speed are adjusted with models to account for missing data and other non-climate factors. The detailed adjustments and corrections are documented in @sec-methodology. For example, precipitation measurements, which are often underestimated, are adjusted to ensure accuracy, especially in regions like the Arctic [@environment_and_climate_change_canada_climate_2021-1]. In the AHCCD dataset, parameters measured are recorded with the units, date, station ids, location and unique identifiers. The AHCCD data maintains a one-to-one correspondence with the historical weather dataset by a matching station id system, ensuring that each entry in the AHCCD aligns directly with a specific observation in the historical dataset. 

The limitations are documented in @sec-methodology.

## Raw Data

In this project, we focus on weather data from YVR Airport, extracting only the datasets containing measurements taken at this specific location from the database. In both datasets, each row corresponds to a single averaged observation for a specific month and year. Each entry includes climate information such as temperature and wind speed, with their respective units recorded alongside the values. Additionally, a unique station ID and geographic coordinates (x, y) are included at the beginning of each entry for reference. The column headers of the raw historical weather dataset is displayed in @tbl-raw-climate. The column headers of the AHCCD dataset is displayed in @tbl-raw-ahccd.

```{r}
#| label: tbl-raw-climate
#| tbl-cap: Column Headers of Raw Climate Data 
#| echo: false
#| warning: false
raw_data <- raw_data_climate

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 3
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

```{r}
#| label: tbl-raw-ahccd
#| tbl-cap: Column Headers of Raw AHCCD Data 
#| echo: false
#| warning: false
raw_data <- raw_data_ahccd

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 2
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

The variables in the two datasets contains the following: 

- Geographical Information: Longitude (x) and Latitude (y), with corresponding identifiers for location (Station Name in @tbl-raw-climate, station_id and province in @tbl-raw-ahccd).
- Temperature Metrics: Mean, maximum, and minimum temperatures (Mean Temp, Mean Max Temp, Mean Min Temp, Extr Max Temp, Extr Min Temp) and associated flags for data validity in @tbl-raw-climate. Similar metrics (temp_mean, temp_max, temp_min) in @tbl-raw-ahccd, with additional units included.
- Precipitation and Snowfall: Total precipitation (Total Precip) and total snow (Total Snow), with flags for data quality in @tbl-raw-climate. Equivalent precipitation and snow variables (total_precip, snow) in @tbl-raw-ahccd, with units explicitly defined.
- Wind and Gust Metrics: Direction and speed of maximum gusts (Dir of Max Gust, Spd of Max Gust) in @tbl-raw-climate, with units and flags. Wind speed (wind_speed) and related metrics in @tbl-raw-ahccd, with units included.
- Pressure Information: Sea level and station pressure variables in @tbl-raw-ahccd (pressure_sea_level, pressure_station) with units.
- Temporal Information: Date and time variables (Date/Time in @tbl-raw-climate, date, period_value in @tbl-raw-ahccd) to track observations across time periods.
- Flags and Identifiers: Flags for data validity in both tables, such as precipitation flags, temperature flags, and identifiers like Climate ID or identifier.


## Data Cleaning {#sec-datacleaning}

The data cleaning process consists of two steps. First, we standardize and clean the column headers. Second, we merge the two datasets into a single combined dataset. The dataset used in this analysis combines information from two distinct sources: climate data (raw_data_climate) and historical weather data (raw_data_ahccd). The analysis spans data collected between 1959 and 2010 for training and testing purposes. 

The cleaned dataset contains a range of weather variables providing detailed monthly observations. The `date` variable represents the observation month, standardized to the first day of each month. **`wind_speed`** (km/h) captures average monthly wind speeds, while **`total_precipitation`** (mm) measures the total monthly precipitation, including rain and snow. **`snow`** (mm) records total snowfall, and **`pressure_station`** (kPa) indicates atmospheric pressure at the observation station. **`max_temp`** (°C), **`min_temp`** (°C), and **`mean_temp`** (°C) represent the monthly averages of maximum, minimum, and overall temperatures, respectively. **`total_rain`** (mm) focuses solely on rainfall amounts, distinct from snowfall. **`gust_speed_km_h`** (km/h) records the monthly average of maximum gust speeds. Additionally, constructed variables include **`mean_temp_F`**, the mean temperature was converted to Fahrenheit using 
$$
(\text{mean\_temp} \times 1.8) + 32
$$
, and **`log_mean_temp`**, the log-transformed Fahrenheit temperature, was calculated as 
$$
\log(\text{mean\_temp\_F})
$$
. 
Additionally, a Box-Cox transformation was applied to the `total_precipitation` variable to address skewness and stabilize variance, resulting in the new variable `total_precipitation_boxcox`. For `gust_speed_km_h`, `wind_speed` and `pressure_station`, a log transformation was used to stabilize variance and reduce right-skewness in their distribution, creating the new variable `log_gust_speed`, `log_wind_speed` and `log_pressure`. 

All column names were cleaned and standardized using `janitor` in tidyverse [@tidyverse] to ensure consistency and readability. Dates were parsed into a unified format (`yyyy-mm-dd`) and aligned with monthly observations using the lubridate package [@lubridate]. The datasets were merged into a single combined dataset using the `date_time` variable as the common key. Finally, constructed variables, including `mean_temp_F`, `total_precipitation_boxcox`, `log_gust_speed`, `log_mean_temp`, `log_wind_speed` and `log_pressure` were added to the cleaned data. 

### Cleaned Data

The top 6 rows of the cleaned data is displayed in @tbl-cleaned-data.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of Cleaned Weather Data
#| tbl-subcap: ['Sample of Cleaned Weather Data', 'Gust Speed and Transformed Data']
#| echo: false
#| warning: false
analysis_data |>
  head(6) |>
  select(
    wind_speed, total_precipitation, snow, pressure_station, 
    max_temp, min_temp, mean_temp, total_rain
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Wind Speed", "Total Precip.", "Snow", "Pressure", 
                  "Max Temp", "Min Temp", "Mean Temp", "Rain"),
    format = "latex", booktabs = TRUE,
  )

analysis_data |>
  head(6) |>
  select(log_gust_speed, log_wind_speed, log_pressure
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Log of Gust Speed", "Log of Wind Speed", "Log of Pressire"),
    format = "latex", booktabs = TRUE,
  )
analysis_data |>
  head(6) |>
  select(
    gust_speed_km_h, log_mean_temp, total_precipitation_boxcox
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Gust Speed", "Log of Mean Temp", "Box-Cox Total Precip."),
    format = "latex", booktabs = TRUE,
  )
```

The summary statistics of the combined dataset is displayed in @tbl-summary.

## Characteristics of Cleaned Data

All of the variables in the dataset are numeric, the histograms are plotted in @fig-hist-temp and @fig-hist-all. The following section explains the characteristics of these variables.

### Skewness in Mean Temperature, Total Precipitation and Gust Speed

```{r}
#| label: fig-hist-temp
#| fig-cap: Mean Temp Shows More Normality and Less Skewness After Adjustment
#| fig-subcap: ['Original Mean Temp has Skewness and Negative Numbers', 'Mean Temp in F Transformed the Value to All Positive', 'Log-Transformed Data Shows a More Symmetric and Less Skewed Distribution']
#| echo: false
#| warning: false
#| layout-ncol: 2
attach(analysis_data)

hist(mean_temp, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°C)", 
     xlab = "Mean Temperature (°C)", 
     col = "red")

# Histogram for Mean Temperature in Fahrenheit
hist(mean_temp_F, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°F)", 
     xlab = "Mean Temperature (°F)", 
     col = "green")

# Histogram for Log of Mean Temperature in Fahrenheit
hist(log_mean_temp, 
     breaks = 100, 
     main = "Log-Transformed Mean Temperature (°F)", 
     xlab = "Log of Mean Temperature (°F)", 
     col = "blue")
```

@fig-hist-temp displays the histogram of the response variable Mean Temperature. @fig-hist-temp-1 shows the original mean temperature, which is skewed and includes negative values, making it unsuitable for direct modeling. To address this, We first transformed the data to Fahrenheit in @fig-hist-temp-2, shifting all values to be positive. However, to further normalize the distribution and reduce skewness, we applied a logarithmic transformation in @fig-hist-temp-3. The log transformation stabilizes variance, improves symmetry, and addresses non-linearity in the data, making it more appropriate for modelling. 

In @fig-hist-all, Transformations are also applied to Wind Speed, Pressure, Total Precipitation and Gust Speed. Total Precipitation has a strong right skew, with most values low and a few extreme high values. We apply log transformation to predictors including wind speed, pressure and precipitation. For Gust Speed, a Box-Cox transformation is applied to adjust its moderate skewness. This transformation reshaped the data to better approximate a normal distribution. These adjustments improve the suitability of these variables for statistical analyses that assume normality. 


### Total Snow Is Zero-Inflated

@fig-boxplot-snow clearly shows significant zero inflation, with a large number of observations concentrated at zero and a few extreme outliers far above the majority of the data. This distribution suggests that the variable snow contains excessive structural zeros, likely representing instances where no snowfall occurred.

<!-- Poor Model Fit: Traditional regression models assume a continuous or discrete distribution of values. The extreme concentration of zeros violates this assumption, leading to biased or inaccurate parameter estimates.
Misleading Interpretability: The effect of snow on the response variable might be confounded by the disproportionate impact of the zeros, making the interpretation of results unreliable.
Violated Assumptions: Many models assume homoscedasticity (constant variance) and normality of residuals. The zero inflation in snow increases heteroscedasticity and skews the residuals.
My bayesian model depends on normal likelihood, so normality and constant variance matters. Gaussian likelihood in your model assumes continuous, symmetric data -->


```{r}
#| label: fig-boxplot-snow
#| fig-cap: Total Snow shows Zero Inflation
#| fig-subcap: ['A Large Proportion of Observations With No Snowfall', 'Prevalence of Zero Values and a Skewed Pattern in the Non-zero Snowfall Measurements']
#| echo: false
#| warning: false
#| layout-ncol: 2
boxplot(analysis_data$snow,
        horizontal = TRUE,
        main = "Boxplot of Total Snow",
        ylab = "Total Snow",
        xlab = "Snow (in cm)", 
        col = "lightblue",
        notch = TRUE)

ggplot(analysis_data, aes(x = snow)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Snow", x = "Snow (cm)", y = "Frequency") +
  theme_minimal()

```

### Variables with Strong Linear Relationships {#sec-multic-all}

#### Maximum Temperature, Minimum Temperature and Mean Temperature {#sec-multic-temp}

@fig-corr-temp-1 highlights strong relationships between temperature variables, showing strong positive correlations between Max Temperature (°C), Min Temperature (°C), and Mean Temperature (°C). Scatter plots in @fig-corr-temp-3 and @fig-corr-temp-4 show near-perfect linear relationships, indicating that Max Temperature (°C) and Min Temperature (°C) are highly collinear with Mean Temperature (°C). In contrast, other predictors shown in @fig-corr-temp-2, such as Wind Speed (km/h), Station Pressure (hPa), and Total Rain (mm), show weaker correlations with the temperature variables and with each other, suggesting they contribute unique and independent information to the model.

```{r}
#| label: fig-corr-temp
#| fig-cap: Temperature Values Have High Correlations
#| fig-subcap: ['High Correlations Between Max, Min and Mean Temperature, Total Precip and Rain', 'Other Predictors Does Not Have High Correlations', 'Linear Relationship Between Max and Mean Temperature', 'Linear Relationship Between Min and Mean Temperature']
#| echo: false
#| warning: false
#| layout-ncol: 2
selected_data_0 <- analysis_data[, c("wind_speed", "pressure_station", "snow",  "min_temp", "log_mean_temp", 'max_temp', "total_rain", "gust_speed_km_h", 'total_precipitation')]
colnames(selected_data_0) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Min Temperature (°C)", "Log Mean Temperature (°F)", 
                               "Max Temperature (°C)", "Total Rain (mm)", 
                               "Gust Speed (km/h)", "Total Precipitation (mm)")

cor_matrix <- cor(selected_data_0)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

selected_data_1 <- analysis_data[, c("wind_speed", "pressure_station", "snow", "log_mean_temp", "total_precipitation", "gust_speed_km_h")]
colnames(selected_data_1) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Log Mean Temperature (°F)", "Total Precip (mm)", 
                               "Gust Speed (km/h)")

cor_matrix <- cor(selected_data_1)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

# Scatter plot with linear trendline for Max Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `max_temp`, y = `mean_temp`)) +
  geom_point(color = "blue", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Max Temperature vs. Mean Temperature",
       x = "Max Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()

# Scatter plot with linear trendline for Min Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `min_temp`, y = `mean_temp`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Min Temperature vs. Mean Temperature",
       x = "Min Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()
```

#### Total Precipitation and Total Rain

Similar to temperature, precipitation and total rain also have a relatively strong linear relationship as illustrated in @fig-corr-rain.

```{r}
#| label: fig-corr-rain
#| fig-cap: Precipitation and Rain Have High Correlations
#| echo: false
#| warning: false

ggplot(analysis_data, aes(x = `total_precipitation`, y = `total_rain`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Total Precipitation vs. Total Rain",
       x = "Total Precipitation (mm)",
       y = "Total Rain (mm)") +
  theme_minimal()
```

# Model

The goal of our modelling strategy is to find a model that can predict temperature changes with other weather data.

We build a bayesian model, a general linear model and a general linear model with a 2 degrees of polynomial transformation. We determine the best model is the linear model with polynomial transformation. The detailed steps are recorded in @sec-model-detail. 

## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

## MLR Model

```{r}
fitted_values <- fitted(m4)
ggplot(data = train_data, aes(x = fitted_values, y = mean_temp_F)) +
  geom_point(color = "blue", alpha = 0.7) +
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed", size = 1) +
  labs(x = "Predicted Temperature", y = "Actual Temperature", title = "Actual Temperature vs. Predicted Values")
```

### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.



# Discussion

## First discussion point {#sec-first-point}

If my paper were 10 pages, then should be be at least 2.5 pages. The discussion is a chance to show off what you know and what you learnt from all this. 

## Second discussion point

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

Weaknesses and next steps should also be included.

\newpage

\appendix
# Appendix {-}

# License
Contains information licensed under the [Open Government Licence – Canada](https://open.canada.ca/en/open-government-licence-canada)

# Model Details {#sec-model-detail}
## MLR Model With Every Predictor in Cleaned Data

The first model predicts mean temperature ($\text{mean\_temp\_F}$) based on multiple predictors: wind speed ($\text{wind\_speed}$), total precipitation ($\text{total\_precipitation}$), snow ($\text{snow}$), station pressure ($\text{pressure\_station}$), maximum temperature ($\text{max\_temp}$), minimum temperature ($\text{min\_temp}$), total rainfall ($\text{total\_rain}$), and gust speed ($\text{gust\_speed\_km\_h}$).

The fitted model is:

\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{total\_precipitation} + \beta_3 \cdot \text{snow} \\
&+ \beta_4 \cdot \text{pressure\_station} + \beta_5 \cdot \text{max\_temp} + \beta_6 \cdot \text{min\_temp} \\
&+ \beta_7 \cdot \text{total\_rain} + \beta_8 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}

- $\beta_0$: Intercept
- $\beta_1, \beta_2, \dots, \beta_8$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in the respective predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This model has the following summary statistics in @tbl-summary-model.

```{r}
#| label: tbl-summary-model
#| tbl-cap: Summary Statistics Shows a Large R2 in Model 1, Potential Variability in Model 2, Model L fits performs than Model 2
#| echo: false
#| warning: false
modelsummary(
  list("Model 1" = m1, "Model 2" = m4, "Model L" = glm_log),
  output = "latex"
)
```

The model's coefficients suggest an issue of multicollinearity, particularly due to the inclusion of highly correlated predictors such as maximum temperature, minimum temperature, and mean temperature, as discussed in @sec-multic-temp. Multicollinearity inflates the standard errors of the coefficients, making it difficult to determine the individual contribution of these variables to the response variable. Despite the model showing a perfect R2 and adjusted R2 , these metrics are misleading because the presence of highly correlated predictors often leads to overfitting. This is evident from the small coefficient magnitudes and nearly zero p-values, which do not reflect the true independent influence of the predictors. Such multicollinearity can undermine the model's interpretability and generalizability to new data.


## MLR Model Without Multicollinearity Variables

We then build our second model. 

This model predicts mean temperature (mean_temp_F) based on a subset of predictors: wind speed (wind_speed), station pressure (pressure_station), total precipitation (total_precipitation), and gust speed (gust_speed_km_h).


\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{pressure\_station} \\
&+ \beta_3 \cdot \text{total\_precipitation} + \beta_4 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}


- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in each respective predictor, holding others constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This simplified model excludes highly correlated predictors, such as maximum and minimum temperatures, to reduce multicollinearity and improve interpretability.

In the summary of our second model as shown in @tbl-summary-model, all predictors have relatively small coefficients, suggesting incremental effects on the response variable. The relatively large standard errors of some coefficients, such as the intercept, indicate potential variability or noise in the data. For instalce, from @fig-hist-temp and @fig-hist-all, we observe skewness and non-normal distribution in both predictor and the response. According to @fig-plot-m4p-1, The model does not sufficiently explain the variability in the response variable, due to non-linearity or unaddressed skewness in the data. This plot suggests that the model's assumptions of linearity and homoscedasticity (constant variance of residuals) are violated.

```{r}
#| label: fig-plot-m4p
#| fig-cap: Residual vs Fitted Plot of Model 2 and L
#| fig-subcap: ['In Model 2, The residuals are not evenly distributed', 'In Model L, The residual is more evenly distributed']
#| echo: false
#| warning: false
#| layout-ncol: 2
plot(m4, which = 1)
plot(glm_log, which = 1)
```

## MLR Model with transformed variables
In our third model L, we use log and Box-Cox transformation to ensure linearity and homoscedasticity in all predictors and the response. The detailed steps are documented in @sec-multic-all. This linear model predicts the log-transformed mean temperature (`log_mean_temp`) based on log-transformed wind speed (`log_wind_speed`), log-transformed pressure (`log_pressure`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

We build our Model L as the following: 

\begin{align}
\text{log\_mean\_temp} &= \beta_0 + \beta_1 \cdot \text{log\_wind\_speed} + \beta_2 \cdot \text{log\_pressure} \\
&+ \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed} + \epsilon
\end{align}

- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in `log_mean_temp` for a one-unit increase in each predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to follow a Gaussian (normal) distribution.

The inclusion of the Box-Cox-transformed total precipitation further refines the model by accommodating non-linearity in precipitation data. The Gaussian family ensures that the residuals of the response variable follow a normal distribution after the transformations. As shown in @fig-plot-m4p-2, this model reduces heteroscedasticity, minimizes non-linear patterns in residuals, and improves overall interpretability and fit. Each coefficient indicates the multiplicative effect of a one-unit change in the respective predictor on the mean temperature after applying the logarithmic transformations. This model fits better than Model 2, as indicated in @tbl-summary-model, as the R2 and adjusted R2 are higher, AIC, BIC are smaller.

## Bayesian Model
After fitting the linear regression model using log and Box-Cox transformations, We extend the analysis by testing a Bayesian regression model (Model B). This model also predicts the log-transformed mean temperature (`log_mean_temp`) but incorporates prior and Bayesian inference to evaluate the uncertainty of parameter estimates. The predictors remain the same: wind speed (`wind_speed`), station pressure (`pressure_station`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

The Bayesian model is defined as:

\begin{align}
\text{log\_mean\_temp} &\sim \mathcal{N}(\mu, \sigma^2), \\
\mu &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{pressure\_station} \\
&\quad + \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed}.
\end{align}

The prior distributions for the parameters are:

- Coefficients ($\beta_1, \beta_2, \beta_3, \beta_4$): 
  $$
  \beta_i \sim \mathcal{N}(0, 10), \quad \text{for } i = 1, 2, 3, 4,
  $$

  reflecting moderate uncertainty centered around zero.

- Intercept ($\beta_0$): 
  $$
  \beta_0 \sim \mathcal{N}(0, 10),
  $$
  indicating prior uncertainty about the baseline log-mean temperature.

The model was fit using **Hamiltonian Monte Carlo (HMC)** via the `brms` package @brm. It uses:
- **4 chains** for convergence,
- **2000 iterations** per chain to ensure stability, 
- **4 cores** for parallel computation, enabling efficient sampling.

## Polynomial Linear Model
The residual plot in @fig-plot-m4p-2 shows a non-linear pattern, as indicated by the curved trend in the residuals. This suggests that the relationship between the predictors and the response variable is not fully captured by a linear model. Adding polynomial terms could help address this non-linearity by allowing the model to fit curved relationships.

# Summary Statistic of cleaned dataset
\newpage
```{r}
#| label: tbl-summary
#| tbl-cap: Summary Statistics of Raw Climate Data 
#| echo: false
#| warning: false
# Generate the table
analysis_data |>
  select(wind_speed, total_precipitation, snow, pressure_station,
  max_temp, min_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Wind Speed", "Total Precipitation", "Snow", "Pres.", 
      "Max Temp", "Min Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(mean_temp, total_rain, gust_speed_km_h,
  mean_temp_F, log_mean_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Mean Temp", "Rain", 
      "Max Gust Speed", "Mean Temp in F", "Log of Mean Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(total_precipitation_boxcox, log_gust_speed, log_wind_speed, log_pressure) |>
  summary() |>
  kable(
    col.names = c(
      "Box Cox of Precipitation", "Log of Gust Speed", "Log of Wind Speed",
      "Log of Pressure"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )

```

\newpage

```{r}
#| label: fig-hist-all
#| fig-cap: Other Variables Show Normal Distribution
#| fig-subcap: ['Wind Speed Shows Symmetric Distribution', 'Total Precipitation Shows Normal Distribution but Skewed Towards Low Values', 'Pressure Station Has a Nearly Normal Distribution', 'Gust Speed Shows Normal Distribution and Moderate Skewness', 'Box-Cox Transformed Precipitation shows Reduces Skewness', 'Log Transformed Gust Speed shows Reduces Skewness', 'Log Transformed Pressure shows Reduces Skewness', 'Log Transformed Wind Speed shows Reduces Skewness']
#| echo: false
#| warning: false
#| layout-ncol: 3

df <- analysis_data

# Plot histogram for wind_speed
ggplot(df, aes(x = wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for total_precipitation
ggplot(df, aes(x = total_precipitation)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Total Precipitation", x = "Total Precipitation (mm)", y = "Frequency") +
  theme_minimal()

# Plot histogram for pressure_station
ggplot(df, aes(x = pressure_station)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = gust_speed_km_h)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for gust_speed_km_h
ggplot(df, aes(x = total_precipitation_boxcox)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Box-Cox of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = log_gust_speed)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for log_pressure
ggplot(df, aes(x = log_pressure)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for wind_speed
ggplot(df, aes(x = log_wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

```

# Additional Model Detail {#sec-model-select}



# Methodology of ECCC {#sec-methodology}

The Adjusted and Homogenized Canadian Climate Data (AHCCD) is a collection of climate datasets developed by @environment_and_climate_change_canada_adjusted_2021. These datasets provide long-term, quality-controlled data that have been adjusted to correct for non-climatic influences.  

## Population, Frame, and Sample 

The population of interest in the AHCCD is the entirety of Canada’s climate data, representing diverse geographical regions and climate conditions. The frame of the dataset are the climatological stations maintained by the ECCC that span across the countries in important locations such as airports, and banks of lakes or rivers. These stations record data on climate elements such as temperature, precipitation, surface pressure, and wind speed over extended periods. The sample is the selected stations across Canada, with adjustments applied to address inconsistencies. The datasets cover periods extending back to 1895 for precipitation, while other variables like wind speed and surface pressure start from 1953 or later. The recorded sample consists of monthly, seasonal, and annual data about surface air temperature, precipitation, pressure, and wind speed, according to @environment_and_climate_change_canada_adjusted_2021. 

## Sample Corrections and Adjustments 

The original data for AHCCD are extracted from the National Climate Data Archive of Environment Canada. These data include daily observations, such as maximum and minimum temperatures, precipitation, surface pressure, and wind speed. Observations are quality-controlled and adjusted to correct for biases due to changes in instruments, observation procedures, and other factors.  

Precipitation data adjustments account for wind undercatch, evaporation, and gauge-specific losses. According to @environment_and_climate_change_canada_climate_2021-1, corrections to account for wind undercatch, evaporation, and gauge specific wetting losses were implemented, especially in snowy conditions where snowfall is not fully captured by standard gauges. Corrections are made with the study by Devine and Mekis.  

Surface air temperature adjustments apply Quantile-Matching techniques to remove inhomogeneities. According to @environment_and_climate_change_canada_climate_2021, With Vincent and Wang's third generation homogenized temperature, Quantile-Matching ensures that the temperature data remain consistent across different periods, even when observation practices change. 

Surface pressure and wind speed data undergo adjustments based on metadata and statistical tests for systematic shifts. According to @environment_and_climate_change_canada_climate_2021-2, wind speed is first adjusted with a logarithmic wind profile, then tested for homogeneity using a technique based on regression models. It involves the identification of variation due to changes in anemometer and location change. The pressure data is corrected due to systematic shifts of non-updated station elevation and relocation, as stated by @environment_and_climate_change_canada_climate_2021-3. 

## Sampling Approach and Trade-offs 

According to the published methodology and the webpage by @dunbar_adjusted_2020, they employ a systematic sampling approach by selecting specific climatological stations with long-term, consistent data records. In some cases, observations from neighboring or overlapping stations are merged to extend time series. The AHCCD dataset may also contain missing values, which can vary depending on the variable, station, and time. Additionally, the AHCCD dataset is site-specific, meaning it provides data specific to individual observation stations.  

## Missing Data Handling 

Non-response, such as gaps in the data due to missing records, is managed by employing statistical and physical methods to homogenize the data. For instance, the AHCCD adjusts for shifts detected through historical evidence and metadata analysis. For large amount of missing data, ECCC mark the data as NA in the dataset [@canadian_centre_for_climate_services_adjusted_2022]. 

## Strengths and Weaknesses 

The AHCCD by @dunbar_adjusted_2020 provides long-term, high-quality climate records adjusted for non-climatic factors such as changes in instrumentation, observation procedures, and station relocations, ensuring consistency and reliability for trend analysis in climate change.  

The documentation acknowledges the possibility of missing values, which naturally arise in long-term observational datasets due to factors such as station interruptions, relocation, or equipment malfunctions [@environment_and_climate_change_canada_adjusted_2021]. Moreover, the dataset’s coverage in Arctic regions is limited to the restricted to the mid-1940s to present, as this limitation reflects the historical absence of earlier systematic observations in these remote regions. 

# Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

\newpage


# References


