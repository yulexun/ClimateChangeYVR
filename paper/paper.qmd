---
title: "My title"
subtitle: "My subtitle if needed"
author: 
  - Lexun Yu
thanks: "Code and data are available at: [https://github.com/yulexun/ClimateChangeYVR](https://github.com/yulexun/ClimateChangeYVR)."
date: today
date-format: long
abstract: "First sentence. Second sentence. Third sentence. Fourth sentence."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(here)
library(arrow)
library(corrplot)
library(knitr)
library(kableExtra)
library(car)
library(modelsummary)
library(brms)
library(Metrics)

raw_data_climate <- read_csv(here("data/01-raw_data/climateyvr.csv"))
raw_data_ahccd <- read_csv(here("data/01-raw_data/ahccdyvr.csv"))
analysis_data <- read_parquet(here("data/02-analysis_data/cleaned_data.parquet"))
train_data <- read_parquet(here("data/02-analysis_data/train_data.parquet"))
test_data <- read_parquet(here("data/02-analysis_data/test_data.parquet"))
m1 <- readRDS(here("models/m1.rds"))
m4 <- readRDS(here("models/m4.rds"))
glm <- readRDS(here("models/glm_poly.rds"))
brm <- readRDS(here("models/brm.rds"))
glm_log <- readRDS(here("models/glm_log.rds"))
```

# Introduction

Climate change is a global challenges today. Patterns such as rising temperatures, shifting weather systems, and increased frequency of severe weather events. In 2021, floods swept through streets in Japanese cities, displacing millions, while extreme heat fueled wildfires in Siberia [@greenpeace_east_asia_5_2021]. Climate change impacts human health, ecosystems, food security, water supplies, and economic stability. Understanding the factors driving temperature changes is necessary for designing effective mitigation strategies. This requires examining the various contributors to temperature variations.

Some scholars have examined the changing climate. @xu_melting_2009 analyze the effects of rising temperatures in the Himalayas, highlighting increased frequency and duration of extreme events and shifts in ecosystems. These changes pose challenges to water supply, agriculture, and human populations. @visser_eliminating_2021 investigates the relationship between precipitation and temperature using data from the Australian Bureau of Meteorology. Visser's regression model indicates that average precipitation intensities increase with temperature, suggesting more intense rainfall in a warmer climate. The role of sea level pressure is also significant. @wills_systematic_2022 note that observed trends in sea level pressure have intensified warming in the Indo-Pacific Warm Pool and caused slight cooling in the eastern equatorial Pacific. However, as @zhang_economic_2017 argue, much of the research has focused on temperature and precipitation. @zhang_economic_2017 expands on this by incorporating additional predictors—relative humidity and wind speed—and concludes, using data from the Ministry of Agriculture of China, that these variables are important in understanding climate dynamics. 

Temperatures significantly impact airport operations. Rising temperatures significantly affect aircraft performance, potentially leading to take-off weight restrictions and the need for longer runways. This directly impacts airport capacity and operations [@coffel_climate_2015]. Temperature forecast models vary in different locations, and different regions have unique climate characteristics that models may not fully capture [@american_meteorological_society_weather_nodate]. 

This research paper aims to identify the factors influencing temperature at Vancouver International Airport and build a model for temperature prediction with the data obtained from @canadian_centre_for_climate_services_adjusted_2022 and @meteorological_service_of_canada_past_2023. Located on the west coast of Richmond, the airport sits on Sea Island, surrounded by water. As a transportation hub for passengers and freight, it is important to assess the location's safety in a warming climate.


Estimand paragraph

Results paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....

The data gathering and analysis is done in R [@citeR] with the following packages: knitr [@knitr], tidyverse [@tidyverse], ggplot2 [@ggplot2], dplyr [@dplyr], arrow [@arrow], here [@here], and lubridate [@lubridate].

# Data {#sec-data}

## Measurement

The measurement of Canadian weather data involves a network of weather stations and data collection methods managed by Environment and Climate Change Canada (ECCC). These stations continuously measure meteorological parameters such as temperature, precipitation, wind speed, and pressure [@meteorological_service_of_canada_past_2023]. We choose the datesets from the Government of Canada for their coverage and quality control processes.

According to the glossary published by @meteorological_service_of_canada_past_2023, Each day, measurement of temperature, rain, snow, precipitation, and gust speed are recorded. The wind and gust speed is measured in km/h with anemometer dials at a standard height of 10 meters above the ground. Rain and precipitation are measured in millimeter using the standard Canadian rain guage, a cylindrical container 40 cm high and 11.3 cm in diameter. Snow is measured in centimeters at several points that appear representative of the immediate area and then averaged. These raw data are combined to one entry and added to the historical climate database with a generated climate id and the station's location and id. Each row also have month and year of the data measured.

For climate research, including climate change studies, @environment_and_climate_change_canada_adjusted_2021 has developed the Adjusted and Homogenized Canadian Climate Data (AHCCD) dataset. This dataset undergoes rigorous quality control and homogenization processes to address non-climatic factors that can affect long-term data consistency, such as station relocations or changes in instrumentation. The AHCCD ensures that observed trends reflect actual climate changes rather than artificial shifts in the data. In the AHCCD dataset, the precipitation, rain, pressure, snow and wind speed are adjusted with models to account for missing data and other non-climate factors. The detailed adjustments and corrections are documented in @sec-methodology. For example, precipitation measurements, which are often underestimated, are adjusted to ensure accuracy, especially in regions like the Arctic [@environment_and_climate_change_canada_climate_2021-1]. In the AHCCD dataset, parameters measured are recorded with the units, date, station ids, location and unique identifiers. The AHCCD data maintains a one-to-one correspondence with the historical weather dataset by a matching station id system, ensuring that each entry in the AHCCD aligns directly with a specific observation in the historical dataset. 

The limitations are documented in @sec-methodology.

## Raw Data

In this project, we focus on weather data from YVR Airport, extracting only the datasets containing measurements taken at this specific location from the database. In both datasets, each row corresponds to a single averaged observation for a specific month and year. Each entry includes climate information such as temperature and wind speed, with their respective units recorded alongside the values. Additionally, a unique station ID and geographic coordinates (x, y) are included at the beginning of each entry for reference. The column headers of the raw historical weather dataset is displayed in @tbl-raw-climate. The column headers of the AHCCD dataset is displayed in @tbl-raw-ahccd.

```{r}
#| label: tbl-raw-climate
#| tbl-cap: Column Headers of Raw Climate Data 
#| echo: false
#| warning: false
raw_data <- raw_data_climate

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 3
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

```{r}
#| label: tbl-raw-ahccd
#| tbl-cap: Column Headers of Raw AHCCD Data 
#| echo: false
#| warning: false
raw_data <- raw_data_ahccd

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 2
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

The variables in the two datasets contains the following: 

- Geographical Information: Longitude (x) and Latitude (y), with corresponding identifiers for location (Station Name in @tbl-raw-climate, station_id and province in @tbl-raw-ahccd).
- Temperature Metrics: Mean, maximum, and minimum temperatures (Mean Temp, Mean Max Temp, Mean Min Temp, Extr Max Temp, Extr Min Temp) and associated flags for data validity in @tbl-raw-climate. Similar metrics (temp_mean, temp_max, temp_min) in @tbl-raw-ahccd, with additional units included.
- Precipitation and Snowfall: Total precipitation (Total Precip) and total snow (Total Snow), with flags for data quality in @tbl-raw-climate. Equivalent precipitation and snow variables (total_precip, snow) in @tbl-raw-ahccd, with units explicitly defined.
- Wind and Gust Metrics: Direction and speed of maximum gusts (Dir of Max Gust, Spd of Max Gust) in @tbl-raw-climate, with units and flags. Wind speed (wind_speed) and related metrics in @tbl-raw-ahccd, with units included.
- Pressure Information: Sea level and station pressure variables in @tbl-raw-ahccd (pressure_sea_level, pressure_station) with units.
- Temporal Information: Date and time variables (Date/Time in @tbl-raw-climate, date, period_value in @tbl-raw-ahccd) to track observations across time periods.
- Flags and Identifiers: Flags for data validity in both tables, such as precipitation flags, temperature flags, and identifiers like Climate ID or identifier.


## Data Cleaning {#sec-datacleaning}

The data cleaning process consists of two steps. First, we standardize and clean the column headers. Second, we merge the two datasets into a single combined dataset. The dataset used in this analysis combines information from two distinct sources: historical weather data (raw_data_climate) and AHCCD weather data (raw_data_ahccd). The analysis spans data collected monthly between August 1959 and August 2010 for training and testing purposes. 

The cleaned dataset contains a range of weather variables providing detailed monthly observations. The `date` variable represents the observation month, standardized to the first day of each month. **`wind_speed`** (km/h) captures average monthly wind speeds, while **`total_precipitation`** (mm) measures the total monthly precipitation, including rain and snow. **`snow`** (mm) records total snowfall, and **`pressure_station`** (kPa) indicates atmospheric pressure at the observation station. **`max_temp`** (°C), **`min_temp`** (°C), and **`mean_temp`** (°C) represent the monthly averages of maximum, minimum, and overall temperatures, respectively. **`total_rain`** (mm) focuses solely on rainfall amounts, distinct from snowfall. **`gust_speed_km_h`** (km/h) records the monthly average of maximum gust speeds. Additionally, constructed variables include **`mean_temp_F`**, the mean temperature was converted to Fahrenheit using 
$$
(\text{mean\_temp} \times 1.8) + 32
$$
, and **`log_mean_temp`**, the log-transformed Fahrenheit temperature, was calculated as 
$$
\log(\text{mean\_temp\_F})
$$
. 
Moreover, a Box-Cox transformation was applied to the `total_precipitation` variable to address skewness and stabilize variance, resulting in the new variable `total_precipitation_boxcox`. For `gust_speed_km_h`, `wind_speed` and `pressure_station`, a log transformation was used to stabilize variance and reduce right-skewness in their distribution, creating the new variable `log_gust_speed`, `log_wind_speed` and `log_pressure`. 

All column names were cleaned and standardized using `janitor` in tidyverse [@tidyverse] to ensure consistency and readability. Dates were parsed into a unified format (`yyyy-mm-dd`) and aligned with monthly observations using the lubridate package [@lubridate]. The datasets were merged into a single combined dataset using the `date_time` variable as the common key. Finally, constructed variables, including `mean_temp_F`, `total_precipitation_boxcox`, `log_gust_speed`, `log_mean_temp`, `log_wind_speed` and `log_pressure` were added to the cleaned data. 

### Cleaned Data and Training/Testing Split

The top 6 rows of the cleaned data is displayed in @tbl-cleaned-data.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of Cleaned Weather Data
#| tbl-subcap: ['Sample of Cleaned Weather Data', 'Gust Speed and Transformed Data']
#| echo: false
#| warning: false
analysis_data |>
  head(6) |>
  select(
    wind_speed, total_precipitation, snow, pressure_station, 
    max_temp, min_temp, mean_temp, total_rain
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Wind Speed", "Total Precip.", "Snow", "Pressure", 
                  "Max Temp", "Min Temp", "Mean Temp", "Rain"),
    format = "latex", booktabs = TRUE,
  )

analysis_data |>
  head(6) |>
  select(log_gust_speed, log_wind_speed, log_pressure
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Log of Gust Speed", "Log of Wind Speed", "Log of Pressire"),
    format = "latex", booktabs = TRUE,
  )
analysis_data |>
  head(6) |>
  select(
    gust_speed_km_h, log_mean_temp, total_precipitation_boxcox
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Gust Speed", "Log of Mean Temp", "Box-Cox Total Precip."),
    format = "latex", booktabs = TRUE,
  )
```

The summary statistics of the combined dataset is displayed in @tbl-summary.

The cleaned and combined dataset is splitted into training group and testing group randomly. The training dataset contains 70% of the cleaned dataset and the testing dataset contains 30% of the cleaned dataset. The training dataset is used to fit the model. The test dataset is used to evaluate the model's performance on unseen data.

## Characteristics of Cleaned Data

All of the variables in the dataset are numeric, the histograms are plotted in @fig-hist-temp and @fig-hist-all. The following section explains the characteristics of these variables.

### Skewness in Variables

```{r}
#| label: fig-hist-temp
#| fig-cap: Mean Temp Shows More Normality and Less Skewness After Adjustment
#| fig-subcap: ['Original Mean Temp has Skewness and Negative Numbers', 'Mean Temp in F Transformed the Value to All Positive', 'Log-Transformed Data Shows a More Symmetric and Less Skewed Distribution']
#| echo: false
#| warning: false
#| layout-ncol: 2
attach(analysis_data)

hist(mean_temp, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°C)", 
     xlab = "Mean Temperature (°C)", 
     col = "red")

# Histogram for Mean Temperature in Fahrenheit
hist(mean_temp_F, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°F)", 
     xlab = "Mean Temperature (°F)", 
     col = "green")

# Histogram for Log of Mean Temperature in Fahrenheit
hist(log_mean_temp, 
     breaks = 100, 
     main = "Log-Transformed Mean Temperature (°F)", 
     xlab = "Log of Mean Temperature (°F)", 
     col = "blue")
```

@fig-hist-temp displays the histogram of the response variable Mean Temperature. @fig-hist-temp-1 shows the original mean temperature, which is skewed and includes negative values, making it unsuitable for direct modeling. To address this, We first transformed the data to Fahrenheit in @fig-hist-temp-2, shifting all values to be positive. However, to further normalize the distribution and reduce skewness, we applied a logarithmic transformation in @fig-hist-temp-3. The log transformation stabilizes variance, improves symmetry, and addresses non-linearity in the data, making it more appropriate for modelling. 

In @fig-hist-all, Transformations are also applied to Wind Speed, Pressure, Total Precipitation and Gust Speed. Total Precipitation has a strong right skew, with most values low and a few extreme high values. We apply log transformation to predictors including wind speed, pressure and precipitation. For Gust Speed, a Box-Cox transformation is applied to adjust its moderate skewness. This transformation reshaped the data to better approximate a normal distribution. These adjustments improve the suitability of these variables for statistical analyses that assume normality. 


### Total Snow Is Zero-Inflated

@fig-boxplot-snow clearly shows significant zero inflation, with a large number of observations concentrated at zero and a few extreme outliers far above the majority of the data. This distribution suggests that the variable snow contains excessive structural zeros, likely representing instances where no snowfall occurred.

<!-- Poor Model Fit: Traditional regression models assume a continuous or discrete distribution of values. The extreme concentration of zeros violates this assumption, leading to biased or inaccurate parameter estimates.
Misleading Interpretability: The effect of snow on the response variable might be confounded by the disproportionate impact of the zeros, making the interpretation of results unreliable.
Violated Assumptions: Many models assume homoscedasticity (constant variance) and normality of residuals. The zero inflation in snow increases heteroscedasticity and skews the residuals.
My bayesian model depends on normal likelihood, so normality and constant variance matters. Gaussian likelihood in your model assumes continuous, symmetric data -->


```{r}
#| label: fig-boxplot-snow
#| fig-cap: Total Snow shows Zero Inflation
#| fig-subcap: ['A Large Proportion of Observations With No Snowfall', 'Prevalence of Zero Values and a Skewed Pattern in the Non-zero Snowfall Measurements']
#| echo: false
#| warning: false
#| layout-ncol: 2
boxplot(analysis_data$snow,
        horizontal = TRUE,
        main = "Boxplot of Total Snow",
        ylab = "Total Snow",
        xlab = "Snow (in cm)", 
        col = "lightblue",
        notch = TRUE)

ggplot(analysis_data, aes(x = snow)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Snow", x = "Snow (cm)", y = "Frequency") +
  theme_minimal()

```

### Variables with Strong Linear Relationships {#sec-multic-all}

#### Maximum Temperature, Minimum Temperature and Mean Temperature {#sec-multic-temp}

@fig-corr-temp-1 highlights strong relationships between temperature variables, showing strong positive correlations between Max Temperature (°C), Min Temperature (°C), and Mean Temperature (°C). Scatter plots in @fig-corr-temp-3 and @fig-corr-temp-4 show near-perfect linear relationships, indicating that Max Temperature (°C) and Min Temperature (°C) are highly collinear with Mean Temperature (°C). In contrast, other predictors shown in @fig-corr-temp-2, such as Wind Speed (km/h), Station Pressure (hPa), and Total Rain (mm), show weaker correlations with the temperature variables and with each other, suggesting they contribute unique and independent information to the model.

```{r}
#| label: fig-corr-temp
#| fig-cap: Temperature Values Have High Correlations
#| fig-subcap: ['High Correlations Between Max, Min and Mean Temperature, Total Precip and Rain', 'Other Predictors Does Not Have High Correlations', 'Linear Relationship Between Max and Mean Temperature', 'Linear Relationship Between Min and Mean Temperature']
#| echo: false
#| warning: false
#| layout-ncol: 2
selected_data_0 <- analysis_data[, c("wind_speed", "pressure_station", "snow",  "min_temp", "log_mean_temp", 'max_temp', "total_rain", "gust_speed_km_h", 'total_precipitation')]
colnames(selected_data_0) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Min Temperature (°C)", "Log Mean Temperature (°F)", 
                               "Max Temperature (°C)", "Total Rain (mm)", 
                               "Gust Speed (km/h)", "Total Precipitation (mm)")

cor_matrix <- cor(selected_data_0)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

selected_data_1 <- analysis_data[, c("wind_speed", "pressure_station", "snow", "log_mean_temp", "total_precipitation", "gust_speed_km_h")]
colnames(selected_data_1) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Log Mean Temperature (°F)", "Total Precip (mm)", 
                               "Gust Speed (km/h)")

cor_matrix <- cor(selected_data_1)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

# Scatter plot with linear trendline for Max Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `max_temp`, y = `mean_temp`)) +
  geom_point(color = "blue", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Max Temperature vs. Mean Temperature",
       x = "Max Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()

# Scatter plot with linear trendline for Min Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `min_temp`, y = `mean_temp`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Min Temperature vs. Mean Temperature",
       x = "Min Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()
```

#### Total Precipitation and Total Rain

Similar to temperature, precipitation and total rain also have a relatively strong linear relationship as illustrated in @fig-corr-rain.

```{r}
#| label: fig-corr-rain
#| fig-cap: Precipitation and Rain Have High Correlations
#| echo: false
#| warning: false

ggplot(analysis_data, aes(x = `total_precipitation`, y = `total_rain`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Total Precipitation vs. Total Rain",
       x = "Total Precipitation (mm)",
       y = "Total Rain (mm)") +
  theme_minimal()
```

# Model {#sec-model}

The goal of our modelling strategy is to find a model that can predict temperature changes with other weather data as predictors such as wind speed, pressure, precipitation and gust speed.

We build a linear model, a bayesian model, and a linear model with a 2 degrees of polynomial transformation. We determine the best model is the linear model with polynomial transformation. The detailed steps are recorded in @sec-model-detail. We choose linear regression instead of general linear model because all of the variables are numeric. According to @kumar_glm_2023, linear regression is applicable when the response is continuous and approximately normally distributed, which is more applicable to our dataset. 

## Model set-up

The final model we choose is the linear model with polynomial transformation.

This polynomial linear regression model predicts the log-transformed mean temperature (`log_mean_temp`) based on quadratic polynomial transformations of four predictors: 

- log-transformed wind speed (`log_wind_speed`), 
- log-transformed pressure (`log_pressure`), 
- Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and 
- log-transformed gust speed (`log_gust_speed`).

The model introduces non-linear relationships by including polynomial terms up to the second degree (quadratic) for each predictor. 

## MLR Model

The Model LP is mathematically expressed as:

\begin{align}
\text{Log Mean Temperature} &= \beta_0 
+ \beta_{1} \cdot \text{Log Wind Speed} + \beta_{2} \cdot (\text{Log Wind Speed})^2 \\
&+ \beta_{3} \cdot \text{Log Pressure} + \beta_{4} \cdot (\text{Log Pressure})^2 \\
&+ \beta_{5} \cdot \text{Box-Cox Total Precipitation} + \beta_{6} \cdot (\text{Box-Cox Total Precipitation})^2 \\
&+ \beta_{7} \cdot \text{Log Gust Speed} + \beta_{8} \cdot (\text{Log Gust Speed})^2 \\
&+ \epsilon
\end{align}

Where: 

1. **Intercept ($\beta_0$):**
   - Represents the baseline log-transformed mean temperature when all predictors are zero.

2. **Predictors and Their Polynomial Terms:**
   - **Wind Speed (Log Wind Speed):**
     - $\beta_{1} \cdot \text{Log Wind Speed}$ models the linear effect of wind speed.
     - $\beta_{2} \cdot (\text{Log Wind Speed})^2$ captures the quadratic (non-linear) effect of wind speed.
   - **Atmospheric Pressure (Log Pressure):**
     - $\beta_{3} \cdot \text{Log Pressure}$ models the linear effect of atmospheric pressure.
     - $\beta_{4} \cdot (\text{Log Pressure})^2$ captures the quadratic effect of atmospheric pressure.
   - **Total Precipitation (Box-Cox Total Precipitation):**
     - $\beta_{5} \cdot \text{Box-Cox Total Precipitation}$ models the linear effect of total precipitation.
     - $\beta_{6} \cdot (\text{Box-Cox Total Precipitation})^2$ captures the quadratic effect of total precipitation.
   - **Gust Speed (Log Gust Speed):**
     - $\beta_{7} \cdot \text{Log Gust Speed}$ models the linear effect of gust speed.
     - $\beta_{8} \cdot (\text{Log Gust Speed})^2$ captures the quadratic effect of gust speed.

3. **Residual Error ($\epsilon$):**
   - Represents the variation in the log-transformed mean temperature that is not explained by the predictors.

The purpose of including polynomial terms in this model is to capture non-linear relationships between the predictors and the response variable, allowing the model to fit more complex, curved patterns that a purely linear model cannot accommodate. By incorporating quadratic terms for each predictor, the model gains flexibility in representing real-world data relationships, reducing bias, and addressing systematic patterns in residuals that may indicate non-linearity. This enhances the model's predictive performance, making it capable of explaining variance that would otherwise remain unaccounted for in a simple linear regression, while still maintaining the interpretability and simplicity of a linear regression framework.

### Model Validation {#sec-validation}

The linear regression model was chosen to analyze the relationship between wind speed, atmospheric pressure, total precipitation, and gust speed with the log-transformed mean temperature. The primary goal of this model is to quantify the effect of each predictor on the response variable and to make predictions. The linear model is suitable because the relationship between the predictors and the response variable was found to be approximately linear after applying logarithmic and Box-Cox transformations to address non-linearity and skewness. 

#### Assumptions Fit the Data

```{r}
#| label: fig-assumption
#| fig-cap: Model LP meets all assumtions of linear regression
#| fig-subcap: ['Linearity Check: Residuals vs Fitted', 'Normality Check: Q-Q Plot', 'Homoscedasticity Check: Scale-Location']
#| echo: false
#| warning: false
#| layout-ncol: 2

plot(glm, which = 1)
plot(glm, which = 2)
plot(glm, which = 3)
```

The model, which uses linear regression, has four assumptions: linearity, homoscedasticity, and approximate normality of residuals. 

The linearity assumption states that the relationship between each predictor and the response variable is linear. This assumption was evaluated by examining scatterplots of the predictors against the response variable and by analyzing residuals versus fitted values. As shown in @fig-assumption-1, The red smooth line indicates only a slight curvature, and the the residuals scatter reasonably randomly around the 0 line. The resulting diagnostic plots showed no obvious systematic patterns, indicating that the linearity assumption is reasonably satisfied.

Homoscedasticity requires that the variance of the residuals remains constant across all levels of the predictors. In @fig-assumption-3, the points (standardized residuals) are evenly spread across the range of fitted values. There is no clear fan or funnel shape, suggesting that the variance of the residuals is fairly constant, which supports the assumption of homoscedasticity.

Linear regression assumes that the residuals follow a normal distribution. This assumption was assessed using Q-Q plots in @fig-assumption-2, where the residuals were compared to a theoretical normal distribution. Most points aligned closely with the diagonal line, indicating that the residuals are approximately normally distributed.

Independence assumes that each observation in the dataset is unrelated to others. This was ensured during data collection or preparation according to ECCC's methodology as discussed in @sec-methodology.

Multicollinearity occurs when predictors are highly correlated, making it difficult to isolate their individual effects. Variance Inflation Factor (VIF) quantifies how much multicollinearity inflates the variance of the estimated regression coefficients. The Generalized VIF (GVIF) is used because each polynomial term represents more than one degree of freedom. The result in @tbl-vif are below the commonly accepted threshold of 5, indicating low multicollinearity in the predictors. 

```{r}
#| label: tbl-vif
#| tbl-cap: VIF Value Indicates Low Multicollinearity
#| echo: false
#| warning: false

# Calculate VIF
vif_values <- vif(glm)
kable(vif_values)
```

#### Validation on Test Data

We validate our Model LP with test data to evaluate the model's generalizability and performance on unseen data. 

The R2 value calculated on the test data ($R^2 = 0.59$) is very close to the R2 value of the model on the training data ($R^2 = 0.61$), as discussed in @sec-result-r2 This similarity indicates that the model generalizes well to unseen data, as its performance on the test set is consistent with its performance during training. The training MSE of 0.0137 and test MSE of 0.0158 indicate the model performs well on both datasets with minimal overfitting. The The small difference between the two R2 values and the small difference between the errors suggests good generalization to unseen data.

```{r}
#| label: tbl-test-validate
#| tbl-cap: R2 and MSE value on test data is close to train data
#| echo: false
#| warning: false

test_data$predicted <- predict(glm, newdata = test_data)
SSR <- sum((test_data$log_mean_temp - test_data$predicted)^2)  # Sum of Squared Residuals
TSS <- sum((test_data$log_mean_temp - mean(test_data$log_mean_temp))^2)  # Total Sum of Squares
R2 <- 1 - (SSR / TSS)
R2T <- summary(glm)$r.squared

train_predictions <- predict(glm, newdata = train_data)
test_predictions <- predict(glm, newdata = test_data)

y_train <- train_data$log_mean_temp
y_test <- test_data$log_mean_temp

mse_train <- mse(y_train, train_predictions)
mse_test <- mse(y_test, test_predictions)

results <- data.frame(
  Metric = c("SSR", "TSS", "R2", "R2-Train", "MSE-Train", "MSE-Test"),
  Value = c(SSR, TSS, R2, R2T, mse_train, mse_test)
)

kable(results)
```

```{r}

```


### Model Justification 

The decision to use a linear regression model with polynomial terms for this analysis is grounded in the need to capture non-linear relationships between the predictors and the log-transformed mean temperature (log_mean_temp). Initial exploratory data analysis and diagnostic plots indicated that the relationships between the predictors, such as log-transformed wind speed, pressure, total precipitation, and gust speed, and the response variable were not strictly linear. Applying second-degree polynomial terms allows the model to account for curvature and interactions within the data while maintaining interpretability.

The polynomial linear regression model was selected over alternative non-linear methods due to its balance between complexity and simplicity. Polynomial terms extend the linear model's capacity to capture non-linear patterns while preserving the interpretability of regression coefficients. The inclusion of transformations, such as logarithmic and Box-Cox, further improves the model by addressing issues of skewness and heteroscedasticity observed in the raw data.

Finally, the model assumptions were rigorously evaluated in @sec-validation. Residual plots confirmed that the linearity assumption was largely met, while the Scale-Location plot and diagnostic tests supported the homoscedasticity of residuals. Variance Inflation Factor (VIF) values for the predictors were all well below the critical threshold, indicating no significant multicollinearity. These results ensure that the model remains valid and reliable for inference and prediction.

# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| label: tbl-modelresults
#| tbl-cap: Summary of Model LP
#| echo: false
#| warning: false
modelsummary(glm)
```

## Intercept Indicates a Strong Baseline In Temperature

The intercept of the model is estimated at **3.899**, representing the predicted value of the log-transformed mean temperature when all predictors are at their mean (after centering and scaling in the polynomial terms). This value serves as the baseline against which the effects of all predictors are measured. A significant intercept indicates the model reliably predicts the baseline log-mean temperature.

## Wind Speed: Non-Linear Increase and Decline in Temperature
The first-degree polynomial term for log-transformed wind speed ($\text{poly(log\_wind\_speed, 2)1}$) has a positive coefficient of **0.260**, suggesting that increasing wind speed is associated with a slight increase in $\log(\text{mean\_temp})$. However, the second-degree term ($\text{poly(log\_wind\_speed, 2)2}$) has a negative coefficient of **-0.449**, indicating a reversing effect at higher wind speeds. This quadratic relationship reflects non-linear relationships between wind speed and temperature.

## Atmospheric Pressure: Consistent Negative Impact on Temperature
Log-transformed atmospheric pressure shows a consistently negative relationship with $\log(\text{mean\_temp})$. The first-degree term ($\text{poly(log\_pressure, 2)1}$) has a coefficient of **-0.388**, and the second-degree term ($\text{poly(log\_pressure, 2)2}$) is more negative at **-0.973**. This indicates that higher atmospheric pressure is associated with a reduction in $\log(\text{mean\_temp})$, and the quadratic term amplifies this effect, particularly at extreme values of pressure.

## Total Precipitation: The Strongest Negative Effect
The Box-Cox transformed total precipitation has the strongest impact on $\log(\text{mean\_temp})$ among all predictors. The first-degree term ($\text{poly(total\_precipitation\_boxcox, 2)1}$) has a significant negative coefficient of **-2.016**, implying that higher precipitation reduces $\log(\text{mean\_temp})$ substantially. The second-degree term ($\text{poly(total\_precipitation\_boxcox, 2)2}$) is positive at **0.218**, indicating a slight mitigation of this negative effect at extreme precipitation levels.

## Gust Speed: Decreases Temperature but Shows Curvature
The first-degree term for log-transformed gust speed ($\text{poly(log\_gust\_speed, 2)1}$) has a negative coefficient of **-0.980**, showing that increasing gust speed reduces $\log(\text{mean\_temp})$. However, the second-degree term ($\text{poly(log\_gust\_speed, 2)2}$) has a positive coefficient of **0.347**, suggesting a minor curvature in the relationship where the negative effect is less pronounced at higher gust speeds.

## Model Metrics: Explains 61% Variance with Low RMSE
The model explains a significant portion of the variance in $\log(\text{mean\_temp})$, as indicated by an $R^2$ value of **0.610** and an adjusted $R^2$ of **0.603**. These values demonstrate that approximately 61% of the variability in $\log(\text{mean\_temp})$ is explained by the predictors, even after accounting for the complexity of the model.

The model has a low RMSE of **0.12**, indicating accurate predictions with minimal average error. The AIC (**-601.2**) and BIC (**-560.6**) values suggest a strong fit compared to alternative models.


# Discussion

## Summary of Results: Precipitation Leads, While Wind and Pressure Add Complexity {#sec-first-point}

This polynomial regression model captures non-linear relationships between predictors and $\log(\text{mean\_temp})$ effectively, with total precipitation exerting the strongest influence. Wind speed and gust speed contribute with both positive and negative effects, depending on the quadratic curvature. Atmospheric pressure consistently shows a negative impact. Despite its strengths, slight evidence of heteroscedasticity and non-linear residual patterns observed in diagnostic plots suggest that future refinements, such as interaction terms or alternative modeling techniques, could improve the model's performance.


## The finding does not agree with Visser
## the finding does match with Wills

Please don't use these as sub-heading labels - change them to be what your point actually is.

## Third discussion point

## Weaknesses and next steps

### Limitations on the Model LP

While the polynomial linear regression model captures much of the relationship between the predictors and the log-transformed mean temperature, some limitations remain. @fig-assumption-1 indicates that the relationship is not completely linear, with minor deviations suggesting that the model may not fully account for certain non-linearities. Additionally, @fig-assumption-3 shows slight evidence of heteroscedasticity at the extreme fitted values, indicating that the variance of residuals is not entirely constant. These limitations suggest that the model could benefit from further refinement, such as applying additional transformations, exploring interaction terms, or using alternative techniques like weighted least squares or robust regression to address potential heteroscedasticity. 
Weaknesses and next steps should also be included.

### Limitation on the Response Mean Temperature

### Limitation on only researching temperature

\newpage

\appendix
# Appendix {-}

# License
Contains information licensed under the [Open Government Licence – Canada](https://open.canada.ca/en/open-government-licence-canada)

# Additional Model Details {#sec-model-detail}
## MLR Model With Every Predictor in Cleaned Data

The first model predicts mean temperature ($\text{mean\_temp\_F}$) based on multiple predictors: wind speed ($\text{wind\_speed}$), total precipitation ($\text{total\_precipitation}$), snow ($\text{snow}$), station pressure ($\text{pressure\_station}$), maximum temperature ($\text{max\_temp}$), minimum temperature ($\text{min\_temp}$), total rainfall ($\text{total\_rain}$), and gust speed ($\text{gust\_speed\_km\_h}$).

The fitted model is:

\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{total\_precipitation} + \beta_3 \cdot \text{snow} \\
&+ \beta_4 \cdot \text{pressure\_station} + \beta_5 \cdot \text{max\_temp} + \beta_6 \cdot \text{min\_temp} \\
&+ \beta_7 \cdot \text{total\_rain} + \beta_8 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}

- $\beta_0$: Intercept
- $\beta_1, \beta_2, \dots, \beta_8$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in the respective predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This model has the following summary statistics in @tbl-summary-model.

```{r}
#| label: tbl-summary-model
#| tbl-cap: Summary Statistics Shows a Large R2 in Model 1, Potential Variability in Model 2, Model L fits performs than Model 2
#| echo: false
#| warning: false
modelsummary(
  list("Model 1" = m1, "Model 2" = m4, "Model L" = glm_log),
  output = "latex"
)
```

The model's coefficients suggest an issue of multicollinearity, particularly due to the inclusion of highly correlated predictors such as maximum temperature, minimum temperature, and mean temperature, as discussed in @sec-multic-temp. Multicollinearity inflates the standard errors of the coefficients, making it difficult to determine the individual contribution of these variables to the response variable. Despite the model showing a perfect R2 and adjusted R2 , these metrics are misleading because the presence of highly correlated predictors often leads to overfitting. This is evident from the small coefficient magnitudes and nearly zero p-values, which do not reflect the true independent influence of the predictors. Such multicollinearity can undermine the model's interpretability and generalizability to new data.


## MLR Model Without Multicollinearity Variables

We then build our second model. 

This model predicts mean temperature (mean_temp_F) based on a subset of predictors: wind speed (wind_speed), station pressure (pressure_station), total precipitation (total_precipitation), and gust speed (gust_speed_km_h).


\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{pressure\_station} \\
&+ \beta_3 \cdot \text{total\_precipitation} + \beta_4 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}


- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in each respective predictor, holding others constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This simplified model excludes highly correlated predictors, such as maximum and minimum temperatures, to reduce multicollinearity and improve interpretability.

In the summary of our second model as shown in @tbl-summary-model, all predictors have relatively small coefficients, suggesting incremental effects on the response variable. The relatively large standard errors of some coefficients, such as the intercept, indicate potential variability or noise in the data. For instalce, from @fig-hist-temp and @fig-hist-all, we observe skewness and non-normal distribution in both predictor and the response. According to @fig-plot-m4p-1, The model does not sufficiently explain the variability in the response variable, due to non-linearity or unaddressed skewness in the data. This plot suggests that the model's assumptions of linearity and homoscedasticity (constant variance of residuals) are violated.

```{r}
#| label: fig-plot-m4p
#| fig-cap: Residual vs Fitted Plot of Model 2 and L
#| fig-subcap: ['In Model 2, The residuals are not evenly distributed', 'In Model L, The residual is more evenly distributed']
#| echo: false
#| warning: false
#| layout-ncol: 2
plot(m4, which = 1)
plot(glm_log, which = 1)
```

## MLR Model with transformed variables
In our third model L, we use log and Box-Cox transformation to ensure linearity and homoscedasticity in all predictors and the response. The detailed steps are documented in @sec-multic-all. This linear model predicts the log-transformed mean temperature (`log_mean_temp`) based on log-transformed wind speed (`log_wind_speed`), log-transformed pressure (`log_pressure`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

We build our Model L as the following: 

\begin{align}
\text{log\_mean\_temp} &= \beta_0 + \beta_1 \cdot \text{log\_wind\_speed} + \beta_2 \cdot \text{log\_pressure} \\
&+ \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed} + \epsilon
\end{align}

- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in `log_mean_temp` for a one-unit increase in each predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to follow a Gaussian (normal) distribution.

The inclusion of the Box-Cox-transformed total precipitation further refines the model by accommodating non-linearity in precipitation data. The Gaussian family ensures that the residuals of the response variable follow a normal distribution after the transformations. As shown in @fig-plot-m4p-2, this model reduces heteroscedasticity, minimizes non-linear patterns in residuals, and improves overall interpretability and fit. Each coefficient indicates the multiplicative effect of a one-unit change in the respective predictor on the mean temperature after applying the logarithmic transformations. This model fits better than Model 2, as indicated in @tbl-summary-model, as the R2 and adjusted R2 are higher, AIC, BIC are smaller.

## Bayesian Model
After fitting the linear regression model using log and Box-Cox transformations, We extend the analysis by testing a Bayesian regression model (Model B). This model also predicts the log-transformed mean temperature (`log_mean_temp`) but incorporates prior and Bayesian inference to evaluate the uncertainty of parameter estimates. The predictors remain the same: wind speed (`wind_speed`), station pressure (`pressure_station`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

The Bayesian model is defined as:

\begin{align}
\text{log\_mean\_temp} &\sim \mathcal{N}(\mu, \sigma^2), \\
\mu &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{pressure\_station} \\
&\quad + \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed}.
\end{align}

The prior distributions for the parameters are:

- Coefficients ($\beta_1, \beta_2, \beta_3, \beta_4$): 
  $$
  \beta_i \sim \mathcal{N}(0, 10), \quad \text{for } i = 1, 2, 3, 4,
  $$

  reflecting moderate uncertainty centered around zero.

- Intercept ($\beta_0$): 
  $$
  \beta_0 \sim \mathcal{N}(0, 10),
  $$

  indicating prior uncertainty about the baseline log-mean temperature.

The model was fit using the `brms` package @brm. It uses:

- 4 chains for convergence,
- 2000 iterations per chain to ensure stability, 
- 4 cores for parallel computation, enabling efficient sampling.

Unlike linear regression, which provides point estimates and assumes fixed parameter values, Bayesian regression incorporates prior knowledge and generates posterior distributions, offering a probabilistic framework that quantifies uncertainty in parameter estimates. 

## The Linear Model has Better Fit than Bayesian Model

We calculate the RMSE value and MAE value of the Bayesian model and the Linear model based on the test dataset, because it evaluates how well the model performs on data it has never seen before, providing a realistic measure of predictive accuracy. 

The RMSE measures the average squared difference between the observed ($y_i$) and predicted ($\hat{y}_i$) values. It is calculated as:

$$
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}
$$

Where:

- $y_i$: The actual value of the $i$-th observation.
- $\hat{y}_i$: The predicted value for the $i$-th observation.
- $n$: The total number of observations.

The MAE measures the average absolute difference between the observed ($y_i$) and predicted ($\hat{y}_i$) values. It is calculated as:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
$$

Where:

- $y_i$: The actual value of the $i$-th observation.
- $\hat{y}_i$: The predicted value for the $i$-th observation.
- $n$: The total number of observations.

By comparing the RMSE and MAE results in @tbl-brm, the Linear Model L has slightly lower RMSE and MAE compared to the Bayesian model, suggesting it has a marginally better fit for the given data. As a result, we choose the Linear Model over the Bayesian Model.


```{r}
#| label: tbl-brm
#| tbl-cap: Summary of Bayesian Model and Comparison of RMSE / MAE on Test Data
#| tbl-subcap: ['Bayesian Model Shows Similar R2 value Compare to Linear', 'Linear Model shows better fit']
#| echo: false
#| warning: false
#| layout-ncol: 2
modelsummary(brm)

# RMSE and MAE
# GLM
glm_model <- glm_log

# BRM
brm_model <- brm

# GLM predictions (reverse log transformation and convert to Celsius)
glm_predictions_log <- predict(glm_model, newdata = test_data)
glm_predictions_F <- exp(glm_predictions_log)  # Predicted in Fahrenheit
glm_predictions <- (glm_predictions_F - 32) * 5 / 9  # Convert to Celsius

# BRM predictions (posterior predictive mean, reverse log transformation and convert to Celsius)
brm_predictions_log <- colMeans(posterior_predict(brm_model, newdata = test_data))
brm_predictions_F <- exp(brm_predictions_log)  # Predicted in Fahrenheit
brm_predictions <- (brm_predictions_F - 32) * 5 / 9  # Convert to Celsius

# Ensure consistency: Predicted and actual values in Celsius
test_data <- test_data %>%
  mutate(
    actual_mean_temp = mean_temp,      # Actual values (Celsius)
    glm_predicted = glm_predictions,  # GLM predictions (Celsius)
    brm_predicted = brm_predictions   # Bayesian predictions (Celsius)
  )

# Calculate RMSE
rmse_glm <- sqrt(mean((test_data$actual_mean_temp - test_data$glm_predicted)^2))
rmse_brm <- sqrt(mean((test_data$actual_mean_temp - test_data$brm_predicted)^2))

# Calculate MAE
mae_glm <- mean(abs(test_data$actual_mean_temp - test_data$glm_predicted))
mae_brm <- mean(abs(test_data$actual_mean_temp - test_data$brm_predicted))

# Create a data frame for the metrics
metrics <- data.frame(
  Model = c("Linear", "Bayesian"),
  RMSE = c(rmse_glm, rmse_brm),
  MAE = c(mae_glm, mae_brm)
)

# Display the table using kable
kable(metrics) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

```

## Polynomial Linear Model
Since we choose the Linear Model L over Bayesian Model, We inspect the residual plot of the linear model. The residual plot in @fig-plot-m4p-2 shows a non-linear pattern, as indicated by the curved trend in the residuals. This suggests that the relationship between the predictors and the response variable is not fully captured by a linear model. Adding polynomial terms could help address this non-linearity by allowing the model to fit curved relationships. The detail of the new model is discussed in @sec-model.

\newpage

# Additional Data Details

The summary statistics of the cleaned data are shown in @tbl-summary.

```{r}
#| label: tbl-summary
#| tbl-cap: Summary Statistics of Raw Climate Data 
#| echo: false
#| warning: false
# Generate the table
analysis_data |>
  select(wind_speed, total_precipitation, snow, pressure_station,
  max_temp, min_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Wind Speed", "Total Precipitation", "Snow", "Pres.", 
      "Max Temp", "Min Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(mean_temp, total_rain, gust_speed_km_h,
  mean_temp_F, log_mean_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Mean Temp", "Rain", 
      "Max Gust Speed", "Mean Temp in F", "Log of Mean Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(total_precipitation_boxcox, log_gust_speed, log_wind_speed, log_pressure) |>
  summary() |>
  kable(
    col.names = c(
      "Box Cox of Precipitation", "Log of Gust Speed", "Log of Wind Speed",
      "Log of Pressure"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )

```

\newpage

As discussed in @sec-data, the histogram of variables before and after transformation is displayed in @fig-hist-all.
```{r}
#| label: fig-hist-all
#| fig-cap: Other Variables Show Normal Distribution
#| fig-subcap: ['Wind Speed Shows Symmetric Distribution', 'Total Precipitation Shows Normal Distribution but Skewed Towards Low Values', 'Pressure Station Has a Nearly Normal Distribution', 'Gust Speed Shows Normal Distribution and Moderate Skewness', 'Box-Cox Transformed Precipitation shows Reduces Skewness', 'Log Transformed Gust Speed shows Reduces Skewness', 'Log Transformed Pressure shows Reduces Skewness', 'Log Transformed Wind Speed shows Reduces Skewness']
#| echo: false
#| warning: false
#| layout-ncol: 3

df <- analysis_data

# Plot histogram for wind_speed
ggplot(df, aes(x = wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for total_precipitation
ggplot(df, aes(x = total_precipitation)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Total Precipitation", x = "Total Precipitation (mm)", y = "Frequency") +
  theme_minimal()

# Plot histogram for pressure_station
ggplot(df, aes(x = pressure_station)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = gust_speed_km_h)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for gust_speed_km_h
ggplot(df, aes(x = total_precipitation_boxcox)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Box-Cox of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = log_gust_speed)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for log_pressure
ggplot(df, aes(x = log_pressure)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for wind_speed
ggplot(df, aes(x = log_wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

```


# Methodology of ECCC {#sec-methodology}

The Adjusted and Homogenized Canadian Climate Data (AHCCD) is a collection of climate datasets developed by @environment_and_climate_change_canada_adjusted_2021. These datasets provide long-term, quality-controlled data that have been adjusted to correct for non-climatic influences.  

## Population, Frame, and Sample 

The population of interest in the AHCCD is the entirety of Canada’s climate data, representing diverse geographical regions and climate conditions. The frame of the dataset are the climatological stations maintained by the ECCC that span across the countries in important locations such as airports, and banks of lakes or rivers. These stations record data on climate elements such as temperature, precipitation, surface pressure, and wind speed over extended periods. The sample is the selected stations across Canada, with adjustments applied to address inconsistencies. The datasets cover periods extending back to 1895 for precipitation, while other variables like wind speed and surface pressure start from 1953 or later. The recorded sample consists of monthly, seasonal, and annual data about surface air temperature, precipitation, pressure, and wind speed, according to @environment_and_climate_change_canada_adjusted_2021. 

## Sample Corrections and Adjustments 

The original data for AHCCD are extracted from the National Climate Data Archive of Environment Canada. These data include daily observations, such as maximum and minimum temperatures, precipitation, surface pressure, and wind speed. Observations are quality-controlled and adjusted to correct for biases due to changes in instruments, observation procedures, and other factors.  

Precipitation data adjustments account for wind undercatch, evaporation, and gauge-specific losses. According to @environment_and_climate_change_canada_climate_2021-1, corrections to account for wind undercatch, evaporation, and gauge specific wetting losses were implemented, especially in snowy conditions where snowfall is not fully captured by standard gauges. Corrections are made with the study by Devine and Mekis.  

Surface air temperature adjustments apply Quantile-Matching techniques to remove inhomogeneities. According to @environment_and_climate_change_canada_climate_2021, With Vincent and Wang's third generation homogenized temperature, Quantile-Matching ensures that the temperature data remain consistent across different periods, even when observation practices change. 

Surface pressure and wind speed data undergo adjustments based on metadata and statistical tests for systematic shifts. According to @environment_and_climate_change_canada_climate_2021-2, wind speed is first adjusted with a logarithmic wind profile, then tested for homogeneity using a technique based on regression models. It involves the identification of variation due to changes in anemometer and location change. The pressure data is corrected due to systematic shifts of non-updated station elevation and relocation, as stated by @environment_and_climate_change_canada_climate_2021-3. 

## Sampling Approach and Trade-offs 

According to the published methodology and the webpage by @dunbar_adjusted_2020, they employ a systematic sampling approach by selecting specific climatological stations with long-term, consistent data records. In some cases, observations from neighboring or overlapping stations are merged to extend time series. The AHCCD dataset may also contain missing values, which can vary depending on the variable, station, and time. Additionally, the AHCCD dataset is site-specific, meaning it provides data specific to individual observation stations.  

## Missing Data Handling 

Non-response, such as gaps in the data due to missing records, is managed by employing statistical and physical methods to homogenize the data. For instance, the AHCCD adjusts for shifts detected through historical evidence and metadata analysis. For large amount of missing data, ECCC mark the data as NA in the dataset [@canadian_centre_for_climate_services_adjusted_2022]. 

## Strengths and Weaknesses 

The AHCCD by @dunbar_adjusted_2020 provides long-term, high-quality climate records adjusted for non-climatic factors such as changes in instrumentation, observation procedures, and station relocations, ensuring consistency and reliability for trend analysis in climate change.  

The documentation acknowledges the possibility of missing values, which naturally arise in long-term observational datasets due to factors such as station interruptions, relocation, or equipment malfunctions [@environment_and_climate_change_canada_adjusted_2021]. Moreover, the dataset’s coverage in Arctic regions is limited to the restricted to the mid-1940s to present, as this limitation reflects the historical absence of earlier systematic observations in these remote regions. 

# Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 

\newpage


# References


