---
title: "Exploring Nonlinear Atmospheric Influences on Temperature Using Polynomial Regression at Vancouver International Airport"
subtitle: "Pressure and Wind as Key Drivers of Temperature Variability, with Limited Impact from Precipitation and Gust Speed"
author: 
  - Lexun Yu
thanks: "Code and data are available at: [https://github.com/yulexun/ClimateChangeYVR](https://github.com/yulexun/ClimateChangeYVR)."
date: today
date-format: long
abstract: "This study investigates how atmospheric factors influence temperature at Vancouver International Airport using a polynomial regression model. The analysis shows that total precipitation has the strongest effect, significantly reducing mean temperature, while wind speed and atmospheric pressure exhibit non-linear and consistent negative impacts, respectively. By explaining 61% of the variability in temperature, the model demonstrates that precipitation, pressure, gust speed and wind speed are key drivers of regional climate patterns. Understanding these relationships helps inform climate adaptation strategies for important infrastructure, including airports, in a warming world."
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(here)
library(arrow)
library(corrplot)
library(knitr)
library(kableExtra)
library(car)
library(modelsummary)
library(brms)
library(Metrics)

raw_data_climate <- read_csv(here("data/01-raw_data/climateyvr.csv"))
raw_data_ahccd <- read_csv(here("data/01-raw_data/ahccdyvr.csv"))
analysis_data <- read_parquet(here("data/02-analysis_data/cleaned_data.parquet"))
train_data <- read_parquet(here("data/02-analysis_data/train_data.parquet"))
test_data <- read_parquet(here("data/02-analysis_data/test_data.parquet"))
m1 <- readRDS(here("models/m1.rds"))
m4 <- readRDS(here("models/m4.rds"))
glm <- readRDS(here("models/glm_poly.rds"))
brm <- readRDS(here("models/brm.rds"))
glm_log <- readRDS(here("models/glm_log.rds"))
```

# Introduction 

Climate change is a global challenge today. Patterns such as rising temperatures, shifting weather systems, and increased frequency of severe weather events. In 2021, floods swept through streets in Japanese cities, displacing millions, while extreme heat fueled wildfires in Siberia [@greenpeace_east_asia_5_2021]. Climate change impacts human health, ecosystems, food security, water supplies, and economic stability. Understanding the factors driving temperature changes is necessary for designing effective mitigation strategies. This requires examining the contributors to temperature variations. 

Some scholars have examined the changing climate. @xu_melting_2009 analyzes the effects of rising temperatures in the Himalayas, highlighting increased frequency and duration of extreme events and shifts in ecosystems. These changes pose challenges to water supply, agriculture, and human populations. @visser_eliminating_2021 investigates the relationship between precipitation and temperature using data from the Australian Bureau of Meteorology. Visser's regression model indicates that average precipitation intensities increase with temperature, suggesting more intense rainfall in a warmer climate. The role of sea level pressure is also significant. @wills_systematic_2022 note that observed trends in sea level pressure have caused slight cooling in the eastern equatorial Pacific. However, as @zhang_economic_2017 argues, much of the research has focused on temperature and precipitation. @zhang_economic_2017 expands on this by incorporating additional predictors—relative humidity and wind speed—and concludes, using data from the Ministry of Agriculture of China, that these variables are important in understanding climate dynamics.  

Temperatures significantly impact airport operations. Rising temperatures significantly affect aircraft performance, leading to take-off weight restrictions and the need for longer runways. This directly impacts airport capacity and operations [@coffel_climate_2015]. Temperature forecast models vary in separate locations, and different regions have unique climate characteristics that models may not fully capture [@american_meteorological_society_weather_nodate].  

This research paper aims to identify the factors influencing temperature at Vancouver International Airport and build a model for temperature prediction with the data obtained from @canadian_centre_for_climate_services_adjusted_2022 and @meteorological_service_of_canada_past_2023. Located on the west coast of Richmond, the airport sits on Sea Island, surrounded by water. As a transportation hub for passengers and freight, it is important to assess the location's safety in a warming climate. 

The estimand in this study is the effect of atmospheric variables, such as wind speed, atmospheric pressure, total precipitation, and gust speed, on the mean temperature at Vancouver International Airport. The goal is to quantify these relationships and predict temperature variations using a polynomial regression model. To account for the non-linear and skewed nature of the data, transformations such as logarithmic and Box-Cox methods were applied to both predictors and the response variable. The estimand reflects how changes in these atmospheric conditions influence log-transformed mean temperature over time. 

The results indicate that total precipitation is the most influential predictor, showing a strong inverse relationship with mean temperature. Wind speed and gust speed demonstrate non-linear effects, with moderate increases associated with temperature rises and higher values contributing to cooling. Pressure consistently exhibits a negative association with temperature, with amplified effects at extreme levels. The model explains 61% of the variance in mean temperature and performs well in validation, showing minimal overfitting and low prediction error. 

These results highlight the role of atmospheric variables in regional temperature changes and the effectiveness of the polynomial regression approach in capturing complex relationships. Our findings contribute to a deeper understanding of regional climate changes, which is important for decision-making and resilience planning in an important nodes in global transportation and logistics, where temperature fluctuations directly influence operational efficiency, safety, and infrastructure planning.

The remainder of this paper is structured as follows: @sec-data provides an overview of the data. @sec-model provides the modeling approach of multiple linear regression with polynomial transformation. We then present our results in @sec-result and discuss the implications, limitations, and future research directions in @sec-discussion.  

The data gathering and analysis is done in R [@citeR] with the following packages: knitr [@knitr], tidyverse [@tidyverse], arrow [@arrow], here [@here], corrplot [@corrplot], kableExtra [@kableExtra], car [@car], modelsummary [@modelsummary], brms [@brms], Metrics [@Metrics]. 

# Data {#sec-data}

## Measurement 

The measurement of Canadian weather data involves a network of weather stations and data collection methods managed by Environment and Climate Change Canada (ECCC). These stations continuously measure meteorological parameters such as temperature, precipitation, wind speed, and pressure [@meteorological_service_of_canada_past_2023]. We choose the datasets from the Government of Canada for their coverage and quality control processes. 

According to the glossary published by @meteorological_service_of_canada_past_2023, Each day, measurement of temperature, rain, snow, precipitation, and gust speed are recorded. The wind and gust speed are measured in km/h with anemometer dials at a standard height of 10 meters above the ground. Rain and precipitation are measured in millimeter using the standard Canadian rain gauge, a cylindrical container 40 cm high and 11.3 cm in diameter. Snow is measured in centimeters at several points that appear representative of the immediate area and then averaged. These raw data are combined to one entry and added to the historical climate database with a generated climate id and the station's location and id. Each row also has the month and year of the data measured. 

For climate research, including climate change studies, @environment_and_climate_change_canada_adjusted_2021 has developed the Adjusted and Homogenized Canadian Climate Data (AHCCD) dataset. This dataset undergoes rigorous quality control and homogenization processes to address non-climatic factors that can affect long-term data consistency, such as station relocations or changes in instrumentation. The AHCCD ensures that observed trends reflect actual climate changes rather than artificial shifts in the data. In the AHCCD dataset, the precipitation, rain, pressure, snow, and wind speed are adjusted with models to account for missing data and other non-climate factors. The detailed adjustments and corrections are documented in @sec-methodology. For example, precipitation measurements, which are often underestimated, are adjusted to ensure accuracy, especially in regions like the Arctic [@environment_and_climate_change_canada_climate_2021-1]. In the AHCCD dataset, parameters measured are recorded with the units, date, station ids, location, and unique identifiers. The AHCCD data maintains a one-to-one correspondence with the historical weather dataset by a matching station id system, ensuring that each entry in the AHCCD aligns directly with a specific observation in the historical dataset.  

The limitations are documented in @sec-methodology. 

## Raw Data 

In this project, we focus on weather data from YVR Airport, extracting only the datasets containing measurements taken at this specific location from the database obtained from @canadian_centre_for_climate_services_adjusted_2022 and @meteorological_service_of_canada_past_2023. In both datasets, each row corresponds to a single averaged observation for a specific month and year. Each entry includes climate information such as temperature and wind speed, with their respective units recorded alongside the values. Additionally, a unique station ID and geographic coordinates (x, y) are included at the beginning of each entry for reference. The column headers of the raw historical weather dataset is displayed in @tbl-raw-climate. The column headers of the AHCCD dataset is displayed in @tbl-raw-ahccd. 

```{r}
#| label: tbl-raw-climate
#| tbl-cap: Column Headers of Raw Climate Data 
#| echo: false
#| warning: false
raw_data <- raw_data_climate

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 3
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

```{r}
#| label: tbl-raw-ahccd
#| tbl-cap: Column Headers of Raw AHCCD Data 
#| echo: false
#| warning: false
raw_data <- raw_data_ahccd

# Get the column names of your data
column_names <- colnames(raw_data)

# Reshape the column names into a matrix with, for example, 4 columns
num_cols <- 2
column_matrix <- matrix(column_names, ncol = num_cols, byrow = TRUE)

# Convert the matrix to a data frame for kable
column_df <- as.data.frame(column_matrix)

# Display in multiple columns with kable
kable(column_df, format = "latex", booktabs = TRUE, col.names = NULL)
```

The variables in the two datasets contains the following: 

- Geographical Information: Longitude (x) and Latitude (y), with corresponding identifiers for location (Station Name in @tbl-raw-climate, station_id and province in @tbl-raw-ahccd).
- Temperature Metrics: Mean, maximum, and minimum temperatures (Mean Temp, Mean Max Temp, Mean Min Temp, Extr Max Temp, Extr Min Temp) and associated flags for data validity in @tbl-raw-climate. Similar metrics (temp_mean, temp_max, temp_min) in @tbl-raw-ahccd, with additional units included.
- Precipitation and Snowfall: Total precipitation (Total Precip) and total snow (Total Snow), with flags for data quality in @tbl-raw-climate. Equivalent precipitation and snow variables (total_precip, snow) in @tbl-raw-ahccd, with units explicitly defined.
- Wind and Gust Metrics: Direction and speed of maximum gusts (Dir of Max Gust, Spd of Max Gust) in @tbl-raw-climate, with units and flags. Wind speed (wind_speed) and related metrics in @tbl-raw-ahccd, with units included.
- Pressure Information: Sea level and station pressure variables in @tbl-raw-ahccd (pressure_sea_level, pressure_station) with units.
- Temporal Information: Date and time variables (Date/Time in @tbl-raw-climate, date, period_value in @tbl-raw-ahccd) to track observations across time periods.
- Flags and Identifiers: Flags for data validity in both tables, such as precipitation flags, temperature flags, and identifiers like Climate ID or identifier.


## Data Cleaning {#sec-datacleaning}

The data cleaning process consists of two steps. First, we standardize and clean the column headers. Second, we merge the two datasets into a single combined dataset. The dataset used in this analysis combines information from two distinct sources: historical weather data (raw_data_climate) and AHCCD weather data (raw_data_ahccd). The analysis spans data collected monthly between August 1959 and August 2010 for training and testing purposes. 

The cleaned dataset has a range of weather variables providing detailed monthly observations. The `date` variable is the observation month, standardized to the first day of each month. **`wind_speed`** (km/h) captures average monthly wind speeds, while **`total_precipitation`** (mm) measures the total monthly precipitation, including rain and snow. **`snow`** (mm) records total snowfall, and **`pressure_station`** (kPa) indicates atmospheric pressure at the observation station. **`max_temp`** (°C), **`min_temp`** (°C), and **`mean_temp`** (°C) represent the monthly averages of maximum, minimum, and overall temperatures, respectively. **`total_rain`** (mm) focuses solely on rainfall amounts, distinct from snowfall. **`gust_speed_km_h`** (km/h) records the monthly average of maximum gust speeds. Additionally, constructed variables include **`mean_temp_F`**, the mean temperature was converted to Fahrenheit using
$$
(\text{mean\_temp} \times 1.8) + 32
$$
, and **`log_mean_temp`**, the log-transformed Fahrenheit temperature, was calculated as 
$$
\log(\text{mean\_temp\_F})
$$
. 
Moreover, a Box-Cox transformation was applied to the `total_precipitation` variable to address skewness and stabilize variance, resulting in the new variable `total_precipitation_boxcox`. For `gust_speed_km_h`, `wind_speed` and `pressure_station`, a log transformation was used to stabilize variance and reduce right-skewness in their distribution, creating the new variable `log_gust_speed`, `log_wind_speed` and `log_pressure`. 

All column names were cleaned and standardized using `janitor` in tidyverse [@tidyverse] to ensure consistency and readability. Dates were parsed into a unified format (`yyyy-mm-dd`) and aligned with monthly observations using the lubridate package [@lubridate]. The datasets were merged into a single combined dataset using the `date_time` variable as the common key. Finally, constructed variables, including `mean_temp_F`, `total_precipitation_boxcox`, `log_gust_speed`, `log_mean_temp`, `log_wind_speed` and `log_pressure` were added to the cleaned data. 

### Cleaned Data and Training/Testing Split

The top 6 rows of the cleaned data are displayed in @tbl-cleaned-data.

```{r}
#| label: tbl-cleaned-data
#| tbl-cap: Sample of Cleaned Weather Data
#| tbl-subcap: ['Sample of Cleaned Weather Data', 'Gust Speed and Transformed Data']
#| echo: false
#| warning: false
analysis_data |>
  head(6) |>
  select(
    wind_speed, total_precipitation, snow, pressure_station, 
    max_temp, min_temp, mean_temp, total_rain
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Wind Speed", "Total Precip.", "Snow", "Pressure", 
                  "Max Temp", "Min Temp", "Mean Temp", "Rain"),
    format = "latex", booktabs = TRUE,
  )

analysis_data |>
  head(6) |>
  select(log_gust_speed, log_wind_speed, log_pressure
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Log of Gust Speed", "Log of Wind Speed", "Log of Pressire"),
    format = "latex", booktabs = TRUE,
  )
analysis_data |>
  head(6) |>
  select(
    gust_speed_km_h, log_mean_temp, total_precipitation_boxcox
  ) |>
  mutate(across(everything(), ~ round(., 2))) |>
  kable(
    col.names = c("Gust Speed", "Log of Mean Temp", "Box-Cox Total Precip."),
    format = "latex", booktabs = TRUE,
  )
```

The summary statistics of the combined dataset are displayed in @tbl-summary.

The cleaned and combined dataset is split into a training group and a testing group randomly. The training dataset contains 70% of the cleaned dataset and the testing dataset contains 30% of the cleaned dataset. The training dataset is used to fit the model. The test dataset is used to evaluate the model's performance on unseen data. 

## Characteristics of Cleaned Data

All variables in the dataset are numeric, the histograms are plotted in @fig-hist-temp and @fig-hist-all. The following section explains the characteristics of these variables.

### Skewness in Variables

```{r}
#| label: fig-hist-temp
#| fig-cap: Mean Temp Shows More Normality and Less Skewness After Adjustment
#| fig-subcap: ['Original Mean Temp has Skewness and Negative Numbers', 'Mean Temp in F Transformed the Value to All Positive', 'Log-Transformed Data Shows a More Symmetric and Less Skewed Distribution']
#| echo: false
#| warning: false
#| layout-ncol: 2
attach(analysis_data)

hist(mean_temp, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°C)", 
     xlab = "Mean Temperature (°C)", 
     col = "red")

# Histogram for Mean Temperature in Fahrenheit
hist(mean_temp_F, 
     breaks = 100, 
     main = "Distribution of Mean Temperature (°F)", 
     xlab = "Mean Temperature (°F)", 
     col = "green")

# Histogram for Log of Mean Temperature in Fahrenheit
hist(log_mean_temp, 
     breaks = 100, 
     main = "Log-Transformed Mean Temperature (°F)", 
     xlab = "Log of Mean Temperature (°F)", 
     col = "blue")
```

@fig-hist-temp displays the histogram of the response variable Mean Temperature. @fig-hist-temp-1 shows the original mean temperature, which is skewed and includes negative values, making it unsuitable for direct modeling. To address this, we first transformed the data to Fahrenheit in @fig-hist-temp-2, shifting all values to be positive. However, to further normalize the distribution and reduce skewness, we applied a logarithmic transformation in @fig-hist-temp-3. The log transformation stabilizes variance, improves symmetry, and addresses non-linearity in the data, making it more appropriate for modelling.  

In @fig-hist-all, Transformations are also applied to Wind Speed, Pressure, Total Precipitation and Gust Speed. Total Precipitation has a strong right skew, with most values low and a few extremely high values. We apply log transformation to predictors including wind speed, pressure, and precipitation. For Gust Speed, a Box-Cox transformation is applied to adjust its moderate skewness. This transformation reshaped the data to better approximate a normal distribution. These adjustments improve the suitability of these variables for statistical analyses that assume normality. 

### Total Snow Is Zero-Inflated

@fig-boxplot-snow clearly shows significant zero inflation, with many observations concentrated at zero and a few extreme outliers far above most of the data. This distribution suggests that the variable snow contains excessive structural zeros, representing instances where no snowfall occurred. 


```{r}
#| label: fig-boxplot-snow
#| fig-cap: Total Snow shows Zero Inflation
#| fig-subcap: ['A Large Proportion of Observations With No Snowfall', 'Prevalence of Zero Values and a Skewed Pattern in the Non-zero Snowfall Measurements']
#| echo: false
#| warning: false
#| layout-ncol: 2
boxplot(analysis_data$snow,
        horizontal = TRUE,
        main = "Boxplot of Total Snow",
        ylab = "Total Snow",
        xlab = "Snow (in cm)", 
        col = "lightblue",
        notch = TRUE)

ggplot(analysis_data, aes(x = snow)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Snow", x = "Snow (cm)", y = "Frequency") +
  theme_minimal()

```

### Variables with Strong Linear Relationships {#sec-multic-all}

#### Maximum Temperature, Minimum Temperature and Mean Temperature {#sec-multic-temp}

@fig-corr-temp-1 highlights strong relationships between temperature variables, showing strong positive correlations between Max Temperature (°C), Min Temperature (°C), and Mean Temperature (°C). Scatter plots in @fig-corr-temp-3 and @fig-corr-temp-4 show near-perfect linear relationships, indicating that Max Temperature (°C) and Min Temperature (°C) are highly collinear with Mean Temperature (°C). In contrast, other predictors shown in @fig-corr-temp-2, such as Wind Speed (km/h), Station Pressure (hPa), and Total Rain (mm), show weaker correlations with the temperature variables and with each other, suggesting they contribute unique and independent information to the model.

```{r}
#| label: fig-corr-temp
#| fig-cap: Temperature Values Have High Correlations
#| fig-subcap: ['High Correlations Between Max, Min and Mean Temperature, Total Precip and Rain', 'Other Predictors Does Not Have High Correlations', 'Linear Relationship Between Max and Mean Temperature', 'Linear Relationship Between Min and Mean Temperature']
#| echo: false
#| warning: false
#| layout-ncol: 2
selected_data_0 <- analysis_data[, c("wind_speed", "pressure_station", "snow",  "min_temp", "log_mean_temp", 'max_temp', "total_rain", "gust_speed_km_h", 'total_precipitation')]
colnames(selected_data_0) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Min Temperature (°C)", "Log Mean Temperature (°F)", 
                               "Max Temperature (°C)", "Total Rain (mm)", 
                               "Gust Speed (km/h)", "Total Precipitation (mm)")

cor_matrix <- cor(selected_data_0)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

selected_data_1 <- analysis_data[, c("wind_speed", "pressure_station", "snow", "log_mean_temp", "total_precipitation", "gust_speed_km_h")]
colnames(selected_data_1) <- c("Wind Speed (km/h)", "Station Pressure (hPa)", "Snow (cm)", 
                               "Log Mean Temperature (°F)", "Total Precip (mm)", 
                               "Gust Speed (km/h)")

cor_matrix <- cor(selected_data_1)
corrplot(cor_matrix, method = "color", type = "upper", 
         tl.col = "black", tl.srt = 45, 
         col = colorRampPalette(c("blue", "white", "red"))(200))

# Scatter plot with linear trendline for Max Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `max_temp`, y = `mean_temp`)) +
  geom_point(color = "blue", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Max Temperature vs. Mean Temperature",
       x = "Max Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()

# Scatter plot with linear trendline for Min Temperature vs. Mean Temperature
ggplot(analysis_data, aes(x = `min_temp`, y = `mean_temp`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Min Temperature vs. Mean Temperature",
       x = "Min Temperature (°C)",
       y = "Mean Temperature (°C)") +
  theme_minimal()
```

#### Total Precipitation and Total Rain

Like temperature, precipitation and total rain also have a strong linear relationship as illustrated in @fig-corr-rain. 

```{r}
#| label: fig-corr-rain
#| fig-cap: Precipitation and Rain Have High Correlations
#| echo: false
#| warning: false

ggplot(analysis_data, aes(x = `total_precipitation`, y = `total_rain`)) +
  geom_point(color = "green", alpha = 0.6) +   # Scatter plot
  geom_smooth(method = "lm", se = FALSE, color = "red") +  # Add linear trendline
  labs(title = "Correlation: Total Precipitation vs. Total Rain",
       x = "Total Precipitation (mm)",
       y = "Total Rain (mm)") +
  theme_minimal()
```

# Model {#sec-model}

The goal of our modelling strategy is to find a model that can predict temperature changes with other weather data as predictors such as wind speed, pressure, precipitation, and gust speed. 

We build a linear model, a Bayesian model, and a linear model with 2 degrees of polynomial transformation. We determine the best model is the linear model with polynomial transformation. The detailed steps are recorded in @sec-model-detail. We choose linear regression instead of the general model because all the variables are numeric. According to @kumar_glm_2023, linear regression is applicable when the response is continuous and normally distributed, which is more applicable to our dataset. 

## Model Set-up

The final model we chose is the linear model with polynomial transformation.

This polynomial linear regression model predicts the log-transformed mean temperature (`log_mean_temp`) based on quadratic polynomial transformations of four predictors: 

- log-transformed wind speed (`log_wind_speed`), 
- log-transformed pressure (`log_pressure`), 
- Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and 
- log-transformed gust speed (`log_gust_speed`).

The model introduces non-linear relationships by including polynomial terms up to the second degree (quadratic) for each predictor. 

The model is fitted with R [@citeR], the Bayesian Model in @sec-model-detail is built using brms [@brms] and rstanarm [@rstanarm]. 

## MLR Polynomial Model

The Model LP is mathematically expressed as:

\begin{align}
\text{Log Mean Temperature} &= \beta_0 
+ \beta_{1} \cdot \text{Log Wind Speed} + \beta_{2} \cdot (\text{Log Wind Speed})^2 \\
&+ \beta_{3} \cdot \text{Log Pressure} + \beta_{4} \cdot (\text{Log Pressure})^2 \\
&+ \beta_{5} \cdot \text{Box-Cox Total Precipitation} + \beta_{6} \cdot (\text{Box-Cox Total Precipitation})^2 \\
&+ \beta_{7} \cdot \text{Log Gust Speed} + \beta_{8} \cdot (\text{Log Gust Speed})^2 \\
&+ \epsilon
\end{align}

Where: 

1. **Intercept ($\beta_0$):**
   - Represents the baseline log-transformed mean temperature when all predictors are zero.

2. **Predictors and Their Polynomial Terms:**
   - **Wind Speed (Log Wind Speed):**
     - $\beta_{1} \cdot \text{Log Wind Speed}$ models the linear effect of wind speed.
     - $\beta_{2} \cdot (\text{Log Wind Speed})^2$ captures the quadratic (non-linear) effect of wind speed.
   - **Atmospheric Pressure (Log Pressure):**
     - $\beta_{3} \cdot \text{Log Pressure}$ models the linear effect of atmospheric pressure.
     - $\beta_{4} \cdot (\text{Log Pressure})^2$ captures the quadratic effect of atmospheric pressure.
   - **Total Precipitation (Box-Cox Total Precipitation):**
     - $\beta_{5} \cdot \text{Box-Cox Total Precipitation}$ models the linear effect of total precipitation.
     - $\beta_{6} \cdot (\text{Box-Cox Total Precipitation})^2$ captures the quadratic effect of total precipitation.
   - **Gust Speed (Log Gust Speed):**
     - $\beta_{7} \cdot \text{Log Gust Speed}$ models the linear effect of gust speed.
     - $\beta_{8} \cdot (\text{Log Gust Speed})^2$ captures the quadratic effect of gust speed.

3. **Residual Error ($\epsilon$):**
   - Represents the variation in the log-transformed mean temperature that is not explained by the predictors.

The purpose of including polynomial terms in this model is to capture non-linear relationships between the predictors and the response variable, allowing the model to fit more complex, curved patterns that a purely linear model cannot accommodate. This enhances the model's predictive performance, making it capable of explaining variance that would otherwise remain unaccounted for in a simple linear regression, while still maintaining the interpretability and simplicity of a linear regression framework.

## Model Validation {#sec-validation}

The linear regression model was chosen to analyze the relationship between wind speed, atmospheric pressure, total precipitation, and gust speed with the log-transformed mean temperature. This model's main goal is to quantify each predictor's effect on the response variable and to make predictions. The linear model is suitable because the relationship between the predictors and the response variable was found to be linear after applying logarithmic and Box-Cox transformations to address non-linearity and skewness. 

### Assumptions Fit the Data

```{r}
#| label: fig-assumption
#| fig-cap: Model LP meets all assumtions of linear regression
#| fig-subcap: ['Linearity Check: Residuals vs Fitted', 'Normality Check: Q-Q Plot', 'Homoscedasticity Check: Scale-Location']
#| echo: false
#| warning: false
#| layout-ncol: 2

plot(glm, which = 1)
plot(glm, which = 2)
plot(glm, which = 3)
```

The model, which uses linear regression, has four assumptions: linearity, homoscedasticity, and approximate normality of residuals.  

The linearity assumption states that the relationship between each predictor and the response variable is linear. This assumption was evaluated by examining scatterplots of the predictors against the response variable and by analyzing residuals versus fitted values. As shown in @fig-assumption-1, The red smooth line indicates only a slight curvature, and the residuals scatter randomly around the 0 line. The resulting diagnostic plots showed no obvious systematic patterns, indicating that the linearity assumption is satisfied. 

Homoscedasticity requires that the variance of the residuals remains constant across all levels of the predictors. In @fig-assumption-3, the points (standardized residuals) are evenly spread across the range of fitted values. There is no clear fan or funnel shape, suggesting the variance of the residuals is constant, which supports the assumption of homoscedasticity. 

Linear regression assumes that the residuals follow a normal distribution. This assumption was assessed using Q-Q plots in @fig-assumption-2, where the residuals were compared to a theoretical normal distribution. Most points aligned closely with the diagonal line, indicating that the residuals are normally distributed. 

Independence assumes that each observation in the dataset is unrelated to others. This was ensured during data collection or preparation according to ECCC's methodology as discussed in @sec-methodology. 

Multicollinearity occurs when predictors are highly correlated, making it difficult to isolate their individual effects. Variance Inflation Factor (VIF) quantifies how much multicollinearity inflates the variance of the estimated regression coefficients. The Generalized VIF (GVIF) is used because each polynomial term represents more than one degree of freedom. The result in @tbl-vif are below the commonly accepted threshold of 5, indicating low multicollinearity in the predictors. 

```{r}
#| label: tbl-vif
#| tbl-cap: VIF Value Indicates Low Multicollinearity
#| echo: false
#| warning: false

# Calculate VIF
vif_values <- vif(glm)
kable(vif_values)
```

### Validation on Test Data

We validate our Model LP with test data to evaluate the model's generalizability and performance on unseen data. 

The R2 value calculated on the test data ($R^2 = 0.59$) is very close to the R2 value of the model on the training data ($R^2 = 0.61$), as discussed in @sec-result-r2 This similarity indicates that the model generalizes well to unseen data, as its performance on the test set is consistent with its performance during training. The training MSE of 0.0137 and test MSE of 0.0158 indicate the model performs well on both datasets with minimal overfitting. The small difference between the two R2 values and the small difference between the errors suggests good generalization to unseen data.

```{r}
#| label: tbl-test-validate
#| tbl-cap: R2 and MSE value on test data is close to train data
#| echo: false
#| warning: false

test_data$predicted <- predict(glm, newdata = test_data)
SSR <- sum((test_data$log_mean_temp - test_data$predicted)^2)  # Sum of Squared Residuals
TSS <- sum((test_data$log_mean_temp - mean(test_data$log_mean_temp))^2)  # Total Sum of Squares
R2 <- 1 - (SSR / TSS)
R2T <- summary(glm)$r.squared

train_predictions <- predict(glm, newdata = train_data)
test_predictions <- predict(glm, newdata = test_data)

y_train <- train_data$log_mean_temp
y_test <- test_data$log_mean_temp

mse_train <- mse(y_train, train_predictions)
mse_test <- mse(y_test, test_predictions)

results <- data.frame(
  Metric = c("SSR", "TSS", "R2", "R2-Train", "MSE-Train", "MSE-Test"),
  Value = c(SSR, TSS, R2, R2T, mse_train, mse_test)
)

kable(results)
```


## Model Justification 

The decision to use a linear regression model with polynomial terms for this analysis is grounded in the need to capture non-linear relationships between the predictors and the log-transformed mean temperature (log_mean_temp). Initial exploratory data analysis and diagnostic plots indicated that the relationships between the predictors, such as log-transformed wind speed, pressure, total precipitation, and gust speed, and the response variable were not strictly linear. Applying second-degree polynomial terms allows the model to account for curvature and interactions within the data while maintaining interpretability. 

The polynomial linear regression model was selected over alternative non-linear methods due to its balance between complexity and simplicity. Polynomial terms extend the linear model's capacity to capture non-linear patterns while preserving the interpretability of regression coefficients. The inclusion of transformations, such as logarithmic and Box-Cox, further improves the model by addressing issues of skewness and heteroscedasticity observed in the raw data. By incorporating quadratic terms for each predictor, the model gains flexibility in representing real-world data relationships, reducing bias, and addressing systematic patterns in residuals that may indicate non-linearity.  

Finally, the model assumptions were evaluated in @sec-validation. Residual plots confirmed that the linearity assumption was met, while the Scale-Location plot and diagnostic tests supported the homoscedasticity of residuals. Variance Inflation Factor (VIF) values for the predictors were all well below the threshold, indicating no significant multicollinearity. These results ensure that the model remains valid and reliable for inference and prediction. 

# Results {#sec-result}

Our results are summarized in @tbl-modelresults, which displays the estimate, standard error, and p-value for each coefficient.

```{r}
#| label: tbl-modelresults
#| tbl-cap: Summary of Model LP
#| echo: false
#| warning: false
modelsummary(glm, statistic = c("Std. Error" = "std.error", "p-value" = "p.value"))
```

## Temperature Conversion

In the analysis, the mean temperature was log-transformed to stabilize variance and improve model interpretability. However, the predicted values from the model are in the log-transformed scale and need to be transformed back to their original scale for practical interpretation. The back-transformation involves exponentiating the predictions to return them to the temperature scale. It is converted with: 

\begin{align}
\text{Temperature (Fahrenheit)} &= e^{\text{log\_mean\_temperature}}
\end{align}

Since the original temperature data is in Fahrenheit, the results must first be converted from the logarithmic scale to Fahrenheit, and then subsequently to Celsius using the standard conversion formula: 

\begin{align}
\text{Temperature (Celsius)} &= (\text{Temperature (Fahrenheit)} - 32) \times \frac{5}{9}
\end{align}​

In this paper, we interpret the result in the model based on the log transformed mean temperature. For practice applications, the temperature predicted must be converted. 

## Coefficients
@fig-coefficients illustrates the estimated coefficients for the polynomial regression model, along with their 95% confidence intervals. Positive coefficients indicate predictors that increase the log-mean temperature, while negative coefficients represent predictors associated with a decrease, with confidence intervals crossing zero suggesting lower statistical significance.

```{r}
#| label: fig-coefficients
#| fig-cap: Intercept Indicates a Strong Baseline (95% CI)
#| echo: false
#| warning: false

coefs <- broom::tidy(glm, conf.int = TRUE)
# Rename terms for better readability
coefs$term <- gsub("poly\\(log_wind_speed, 2\\)", "Wind Speed (Poly)", coefs$term)
coefs$term <- gsub("poly\\(log_pressure, 2\\)", "Pressure (Poly)", coefs$term)
coefs$term <- gsub("poly\\(total_precipitation_boxcox, 2\\)", "Precipitation (Poly)", coefs$term)
coefs$term <- gsub("poly\\(log_gust_speed, 2\\)", "Gust Speed (Poly)", coefs$term)

ggplot(coefs, aes(x = term, y = estimate, ymin = conf.low, ymax = conf.high)) +
  geom_pointrange() +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  coord_flip() +  # Flip the axes for better readability
  labs(
    title = "Coefficient Estimates with Confidence Intervals",
    x = "Predictor Terms",
    y = "Estimate"
  ) +
  theme_minimal()
```

### Intercept Indicates a Strong Baseline In Temperature

The intercept of the model is estimated at **3.899**, representing the predicted value of the log-transformed mean temperature when all predictors are at their mean (after centering and scaling in the polynomial terms). This value serves as the baseline against which the effects of all predictors are measured. A significant intercept indicates the model reliably predicts the baseline log-mean temperature.

### Wind Speed: Non-Linear Increase and Decline in Temperature
The first-degree polynomial term for log-transformed wind speed ($\text{poly(log\_wind\_speed, 2)1}$) has a positive coefficient of **0.260**, suggesting that increasing wind speed is associated with a slight increase in $\log(\text{mean\_temp})$. However, the second-degree term ($\text{poly(log\_wind\_speed, 2)2}$) has a negative coefficient of **-0.449**, indicating a reversing effect at higher wind speeds. This quadratic relationship reflects non-linear relationships between wind speed and temperature.

### Atmospheric Pressure: Consistent Negative Impact on Temperature
Log-transformed atmospheric pressure shows a consistently negative relationship with $\log(\text{mean\_temp})$. The first-degree term ($\text{poly(log\_pressure, 2)1}$) has a coefficient of **-0.388**, and the second-degree term ($\text{poly(log\_pressure, 2)2}$) is more negative at **-0.973**. This indicates that higher atmospheric pressure is associated with a reduction in $\log(\text{mean\_temp})$, and the quadratic term amplifies this effect, particularly at extreme values of pressure.

### Total Precipitation: The Strongest Negative Effect
The Box-Cox transformed total precipitation has the strongest impact on $\log(\text{mean\_temp})$ among all predictors. The first-degree term ($\text{poly(total\_precipitation\_boxcox, 2)1}$) has a significant negative coefficient of **-2.016**, implying that higher precipitation reduces $\log(\text{mean\_temp})$ substantially. The second-degree term ($\text{poly(total\_precipitation\_boxcox, 2)2}$) is positive at **0.218**, indicating a slight mitigation of this negative effect at extreme precipitation levels.

### Gust Speed: Decreases Temperature but Shows Curvature
The first-degree term for log-transformed gust speed ($\text{poly(log\_gust\_speed, 2)1}$) has a negative coefficient of **-0.980**, showing that increasing gust speed reduces $\log(\text{mean\_temp})$. However, the second-degree term ($\text{poly(log\_gust\_speed, 2)2}$) has a positive coefficient of **0.347**, suggesting a minor curvature in the relationship where the negative effect is less pronounced at higher gust speeds.

### Model Metrics: Explains 61% Variance with Low RMSE {#sec-result-r2}
The model explains a significant portion of the variance in $\log(\text{mean\_temp})$, as indicated by an $R^2$ value of **0.610** and an adjusted $R^2$ of **0.603**. These values demonstrate that approximately 61% of the variability in $\log(\text{mean\_temp})$ is explained by the predictors, even after accounting for the complexity of the model.

The model has a low RMSE of **0.12**, indicating accurate predictions with minimal average error. The AIC (**-601.2**) and BIC (**-560.6**) values suggest a strong fit compared to alternative models.

## Predicted vs. Actual Plot Shows Consistent Performance of the Model

```{r}
#| label: fig-predictedvsfit
#| fig-cap: Predicted vs. Actual plot shows good fit
#| fig-subcap: ['The model is accurate in the train data', 'The model is accurate in the test data']
#| echo: false
#| warning: false
#| layout-ncol: 2
#| 
train_data$predicted <- predict(glm, newdata = train_data)
test_data$predicted <- predict(glm, newdata = test_data)

ggplot(train_data, aes(x = log_mean_temp, y = predicted)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs Actual Log Mean Temperature",
       x = "Actual Log Mean Temperature",
       y = "Predicted Log Mean Temperature") +
  theme_minimal()
ggplot(test_data, aes(x = log_mean_temp, y = predicted)) +
  geom_point(alpha = 0.6) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Predicted vs Actual Log Mean Temperature",
       x = "Actual Log Mean Temperature",
       y = "Predicted Log Mean Temperature") +
  theme_minimal()
```

As displayed in @fig-predictedvsfit, the predicted vs. actual plots for both the training and test datasets demonstrate a strong alignment along the diagonal. In @fig-predictedvsfit-1, The points closely align along the red diagonal line, indicating that the model predictions are highly accurate for the training dataset. In @fig-predictedvsfit-2, the test dataset shows a comparable trend, with predictions aligning well with actual values, suggesting the model generalizes effectively to unseen data. These results confirm that the model provides a good fit for the response variable in both datasets.

## P-value

In @tbl-modelresults, the p-value in regression results show that several coefficients are statistically significant at the 0.05 level, and all coefficients are significant at the 0.1 level. The intercept and terms for the second-degree polynomials of log_pressure and total_precipitation_boxcox are highly significant (p < 0.001). Similarly, the second-degree term of log_gust_speed (p = 0.00496) and the first-degree term of log_pressure (p = 0.00337) are significant at the 0.01 level. Marginal significance is observed for the first-degree terms of log_wind_speed (p = 0.0721) and total_precipitation_boxcox (p = 0.0716).

# Discussion {#sec-discussion}

This paper examines the factors influencing mean temperature at Vancouver International Airport using data collected from Environment and Climate Change Canada. A polynomial regression model was developed to predict log-transformed mean temperature based on atmospheric predictors, including wind speed, atmospheric pressure, total precipitation, and gust speed. These variables were transformed using logarithmic or Box-Cox methods to stabilize variance and address non-linearity in their relationships with temperature. 

The analysis included detailed data preparation, combining raw observational datasets with adjusted and homogenized climate data. The dataset was cleaned, standardized, and split into training and test groups to ensure robust model validation. Exploratory data analysis found skewness and zero inflation in several predictors, needing transformations for improved model suitability. 

The study focused on building a polynomial regression model. By incorporating quadratic terms for all predictors, the model captured non-linear relationships and explained 61% of the variance in mean temperature. Model performance was evaluated through diagnostic tests, residual analysis, and comparisons of predicted versus actual values. Metrics such as RMSE confirmed the model's accuracy and generalizability to unseen data. 

## Summary of Results
### Precipitation Leads, While Wind and Pressure Add Complexity {#sec-first-point}

This study identified total precipitation as the strongest predictor of temperature variation, demonstrating a robust inverse relationship with mean temperature. The analysis showed that wind speed and gust speed have non-linear effects, with the direction and magnitude of their impact dependent on the quadratic terms included in the model. Atmospheric pressure consistently reduced temperature, with the quadratic term further emphasizing this effect at extreme levels of pressure. The inclusion of polynomial terms allowed the model to address curvatures in relationships that linear terms alone could not capture. The model performed well, explaining 61% of the variance and maintaining its accuracy across training and test datasets. The low RMSE confirms the model's ability to approximate observed temperatures effectively. 

These results reflect the complexity of meteorological interactions influencing temperature. While total precipitation emerged as the dominant factor, the important roles of wind and pressure underscore the importance of considering multiple predictors simultaneously. Together, these variables reflect the dynamics influencing temperature at Vancouver International Airport (YVR).

### Non-Linear Effects of Atmospheric Predictors on Temperature
The study highlights a non-linear relationship between predictors, such as wind speed, and mean temperature. For instance, at moderate wind speeds, the findings suggest a slight increase in temperature, potentially due to enhanced mixing of atmospheric layers that can bring warmer air from aloft. However, as wind speed increases further, its effect reverses, leading to a decrease in temperature. This could be attributed to the cooling influence of stronger winds dispersing heat more effectively or increasing evaporation rates. These findings suggest the importance of accounting for non-linear effects in predictive climate models, as linear assumptions would overlook such complex dynamics. Further research could inspect how wind speed interacts with other variables, such as humidity or surface characteristics, to influence temperature.

### Dominance of Precipitation in Predicting Temperature Variation

The analysis identifies precipitation as the most influential factor in predicting temperature changes, with a strong inverse relationship observed. This result is consistent with the idea that precipitation events often coincide with increased cloud cover, which limits solar radiation and leads to cooler surface temperatures. Additionally, evaporative cooling during and after precipitation events may further contribute to this effect. The quadratic nature of the precipitation term suggests diminishing effects at extreme levels, which could reflect saturation in cooling mechanisms or localized anomalies in precipitation patterns. These findings emphasize the role of hydrological processes in modulating regional climate and provide a basis for refining climate prediction models to incorporate precipitation variability more effectively.

## Comparing with Previous Studies
### Our finding does not aligh with Visser
The findings diverge from the work of @visser_eliminating_2021, who identified a positive association between precipitation intensity and temperature in Australia. This contrast highlights the importance of regional climatic differences and suggests that factors such as geographic features, prevailing weather patterns, and local topography may alter these relationships. For example, Vancouver's coastal climate likely moderates precipitation's impact on temperature compared to Australia's arid and semi-arid conditions.

### Our finding align with Wills
Our results align with @wills_systematic_2022, who identified atmospheric pressure as a cooling factor in equatorial Pacific regions. This consistency reinforces the broader applicability of pressure-temperature relationships in diverse climatic contexts. The agreement with Wills suggests that pressure effects may operate at larger spatial scales, transcending localized conditions.

## Weaknesses and Future Directions

### Limitations on the Model LP

While the polynomial linear regression model captures much of the relationship between the predictors and the log-transformed mean temperature, some limitations remain. @fig-assumption-1 indicates that the relationship is not completely linear, with minor deviations suggesting that the model may not fully account for certain non-linearities. Additionally, @fig-assumption-3 shows slight evidence of heteroscedasticity at the extreme fitted values, indicating that the variance of residuals is not entirely constant. These limitations suggest that the model could benefit from further refinement, such as applying additional transformations, inspecting interaction terms, or using alternative techniques like weighted least squares or robust regression to address potential heteroscedasticity. 

### Limitation on the Response Log Transformed Mean Temperature

The temperature in the model is transformed, which adds complexity for real world applications. Moreover, the use of mean temperature as the sole response variable, though practical, limits the information gained. Mean temperature smooths out extremes, thereby overlooking information about temperature variability. Extremes, such as maximum and minimum temperatures, play a significant role in understanding climate impacts, particularly in terms of heatwaves or freezing conditions.  

Future research could expand the scope of the analysis to include a range of temperature metrics. Analyzing temperature extremes or variability measures, such as diurnal temperature range or seasonal deviations, would provide a richer understanding of atmospheric influences on climate. Incorporating additional response variables could also show interactions between predictors that are not apparent when analyzing mean temperature alone. 

### Limitation on Using Temperature as the only Response

As @coffel_climate_2015 discussed, using mean temperature as the sole response variable, while good for general climate modeling, presents limitations when assessing airport safety. Aviation safety is influenced not just by average temperature but also by its variability, particularly extremes that can significantly impact operations. For example, high maximum temperatures reduce air density, affecting aircraft lift during takeoff. Similarly, low minimum temperatures can lead to ice formation on runways and aircraft surfaces, posing safety hazards. Atmospheric conditions that affect aviation, such as wind speed and sea level pressure, are not captured by mean temperature alone. These variables are directly tied to operational challenges and safety considerations.

For instance, wind speed is a major factor in airport operations, influencing takeoff, landing, and overall flight stability. Sudden changes in wind speed or direction, including gusts and crosswinds, can compromise safety and require adjustments in scheduling and runway usage. Analyzing wind speed alongside temperature would provide a better understanding of the conditions that lead to unsafe situations.

Sea level pressure is another important variable, affecting aircraft performance and weather systems. Variations in pressure can lead to storms, precipitation, or clear but frigid conditions that impact runway conditions and aircraft operation. Low-pressure systems often bring intense winds and poor visibility, while high-pressure systems can lead to temperature extremes that influence infrastructure and fuel performance. 

Including wind speed and sea level pressure in future analyses would enhance the ability to assess and predict conditions relevant to airport safety. These variables are fundamental to the aviation sector and provide a more detailed view of the atmospheric dynamics that affect operations. Addressing these factors would align the study with the needs of airport safety management and planning.

### Limitation on ECCC's methodology
The reliance on Environment and Climate Change Canada (ECCC) adjusted and homogenized climate data introduces methodological constraints. While these datasets are extensively quality-controlled, they are subject to adjustments for station relocations, instrument changes, and missing data imputation as discussed in @sec-methodology. Such adjustments, while necessary, could obscure trends or introduce biases that might not reflect current climate conditions. This is especially relevant when studying localized phenomena where raw observational data might show small scale of changes. 

To address these concerns, future research could compare adjusted datasets with raw, unprocessed data. Integrating alternative data sources, such as satellite-derived measurements or high-resolution reanalysis products, might complement the ECCC data. Furthermore, temporal limitations of the dataset, such as monthly aggregation, restrict the analysis of short-term weather events. Employing higher temporal resolution data, such as hourly or daily measurements, would allow for a detailed examination of precipitation and temperature interactions over shorter time scales.

### Potential Directions for Expanded Analysis
Expanding this research to include airports in different regions around the world would provide a broader understanding of how variables influence airport safety. Airports operate in different climatic and geographic conditions such as coastal locations and high-altitude terrains, have unique challenges influenced by local weather patterns. Investigating these variations could show patterns and trends that are not observable when focusing on Vancouver's airport.

For instance, airports in tropical regions might experience high wind speeds and pressure fluctuations due to frequent storms, whereas those in colder regions are more likely to face challenges related to low temperatures and ice. Conducting similar analyses at airports in different environments could show how predictors like wind speed, sea level pressure, and temperature interact under different climatic regimes.

Additionally, comparing airports with varying altitudes and proximity to water would allow researchers to inspect the role of geographical features in modifying atmospheric conditions. For example, high-altitude airports may be more affected by low atmospheric pressure, while coastal airports might experience more significant impacts from wind and precipitation variability.

\newpage

\appendix
# Appendix {-}

# License
Contains information licensed under the [Open Government Licence – Canada](https://open.canada.ca/en/open-government-licence-canada).

# Additional Model Details {#sec-model-detail}
## MLR Model with Every Predictor in Cleaned Data

The first model predicts mean temperature ($\text{mean\_temp\_F}$) based on multiple predictors: wind speed ($\text{wind\_speed}$), total precipitation ($\text{total\_precipitation}$), snow ($\text{snow}$), station pressure ($\text{pressure\_station}$), maximum temperature ($\text{max\_temp}$), minimum temperature ($\text{min\_temp}$), total rainfall ($\text{total\_rain}$), and gust speed ($\text{gust\_speed\_km\_h}$).

The fitted model is:

\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{total\_precipitation} + \beta_3 \cdot \text{snow} \\
&+ \beta_4 \cdot \text{pressure\_station} + \beta_5 \cdot \text{max\_temp} + \beta_6 \cdot \text{min\_temp} \\
&+ \beta_7 \cdot \text{total\_rain} + \beta_8 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}

- $\beta_0$: Intercept
- $\beta_1, \beta_2, \dots, \beta_8$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in the respective predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This model has the following summary statistics in @tbl-summary-model.

```{r}
#| label: tbl-summary-model
#| tbl-cap: Summary Statistics Shows a Large R2 in Model 1, Potential Variability in Model 2, Model L fits performs than Model 2
#| echo: false
#| warning: false
modelsummary(
  list("Model 1" = m1, "Model 2" = m4, "Model L" = glm_log),
  output = "latex"
)
```

The model's coefficients suggest an issue of multicollinearity, particularly due to the inclusion of highly correlated predictors such as maximum temperature, minimum temperature, and mean temperature, as discussed in @sec-multic-temp. Multicollinearity inflates the standard errors of the coefficients, making it difficult to determine the individual contribution of these variables to the response variable. Despite the model showing a perfect R2 and adjusted R2, these metrics are misleading because the presence of highly correlated predictors often leads to overfitting. This is evident from the small coefficient magnitudes and nearly zero p-values, which do not reflect the true independent influence of the predictors. Such multicollinearity can undermine the model's interpretability and generalizability to new data.


## MLR Model Without Multicollinearity Variables

We then build our second model. 

This model predicts mean temperature (mean_temp_F) based on a subset of predictors: wind speed (wind_speed), station pressure (pressure_station), total precipitation (total_precipitation), and gust speed (gust_speed_km_h).


\begin{align}
\text{mean\_temp\_F} &= \beta_0 + \beta_1 \cdot \text{wind\_speed} + \beta_2 \cdot \text{pressure\_station} \\
&+ \beta_3 \cdot \text{total\_precipitation} + \beta_4 \cdot \text{gust\_speed\_km\_h} + \epsilon
\end{align}


- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in $\text{mean\_temp\_F}$ for a one-unit increase in each respective predictor, holding others constant.
- $\epsilon$: Residual error, assumed to be normally distributed with mean 0.

This simplified model excludes highly correlated predictors, such as maximum and minimum temperatures, to reduce multicollinearity and improve interpretability.

In the summary of our second model as shown in @tbl-summary-model, all predictors have small coefficients, suggesting incremental effects on the response variable. The large standard errors of some coefficients, such as the intercept, indicate potential variability or noise in the data. For instance, from @fig-hist-temp and @fig-hist-all, we observe skewness and non-normal distribution in both predictor and the response. According to @fig-plot-m4p-1, The model does not sufficiently explain the variability in the response variable, due to non-linearity or unaddressed skewness in the data. This plot suggests that the model's assumptions of linearity and homoscedasticity (constant variance of residuals) are violated. 

```{r}
#| label: fig-plot-m4p
#| fig-cap: Residual vs Fitted Plot of Model 2 and L
#| fig-subcap: ['In Model 2, The residuals are not evenly distributed', 'In Model L, The residual is more evenly distributed']
#| echo: false
#| warning: false
#| layout-ncol: 2
plot(m4, which = 1)
plot(glm_log, which = 1)
```

## MLR Model with transformed variables
In our third model L, we use log and Box-Cox transformation to ensure linearity and homoscedasticity in all predictors and the response. The detailed steps are documented in @sec-multic-all. This linear model predicts the log-transformed mean temperature (`log_mean_temp`) based on log-transformed wind speed (`log_wind_speed`), log-transformed pressure (`log_pressure`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

We build our Model L as the following: 

\begin{align}
\text{log\_mean\_temp} &= \beta_0 + \beta_1 \cdot \text{log\_wind\_speed} + \beta_2 \cdot \text{log\_pressure} \\
&+ \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed} + \epsilon
\end{align}

- $\beta_0$: Intercept.
- $\beta_1, \beta_2, \beta_3, \beta_4$: Coefficients representing the change in `log_mean_temp` for a one-unit increase in each predictor, holding other variables constant.
- $\epsilon$: Residual error, assumed to follow a Gaussian (normal) distribution.

The inclusion of the Box-Cox-transformed total precipitation further refines the model by accommodating non-linearity in precipitation data. The Gaussian family ensures that the residuals of the response variable follow a normal distribution after the transformations. As shown in @fig-plot-m4p-2, this model reduces heteroscedasticity, minimizes non-linear patterns in residuals, and improves overall interpretability and fit. Each coefficient indicates the multiplicative effect of a one-unit change in the respective predictor on the mean temperature after applying the logarithmic transformations. This model fits better than Model 2, as indicated in @tbl-summary-model, as the R2 and adjusted R2 are higher, AIC, BIC are smaller.

## Bayesian Model
After fitting the linear regression model using log and Box-Cox transformations, we extend the analysis by testing a Bayesian regression model (Model B). This model also predicts the log-transformed mean temperature (`log_mean_temp`) but incorporates prior and Bayesian inference to evaluate the uncertainty of parameter estimates. The predictors remain the same: wind speed (`wind_speed`), station pressure (`pressure_station`), Box-Cox-transformed total precipitation (`total_precipitation_boxcox`), and log-transformed gust speed (`log_gust_speed`).

The Bayesian model is defined as:

\begin{align}
\text{log\_mean\_temp} &\sim \mathcal{N}(\mu, \sigma^2), \\
\mu &= \beta_0 + \beta_1 \cdot \text{log\_wind\_speed} + \beta_2 \cdot \text{log\_pressure\_station} \\
&\quad + \beta_3 \cdot \text{total\_precipitation\_boxcox} + \beta_4 \cdot \text{log\_gust\_speed}.
\end{align}

The prior distributions for the parameters are:

- Coefficients ($\beta_1, \beta_2, \beta_3, \beta_4$): 
  $$
  \beta_i \sim \mathcal{N}(0, 10), \quad \text{for } i = 1, 2, 3, 4,
  $$

  reflecting moderate uncertainty centered around zero.

- Intercept ($\beta_0$): 
  $$
  \beta_0 \sim \mathcal{N}(0, 10),
  $$

  indicating prior uncertainty about the baseline log-mean temperature.

The model was fit using the `brms` package [@brms]. It uses:

- 4 chains for convergence,
- 2000 iterations per chain to ensure stability, 
- 4 cores for parallel computation, enabling efficient sampling.

Unlike linear regression, which provides point estimates and assumes fixed parameter values, Bayesian regression incorporates prior knowledge and generates posterior distributions, giving a probabilistic framework that quantifies uncertainty in parameter estimates. 

## The Linear Model Has Better Fit than Bayesian Model

We calculate the RMSE value and MAE value of the Bayesian model, and the Linear model based on the test dataset, because it evaluates how well the model performs on data it has never seen before, providing a realistic measure of predictive accuracy. 

The RMSE measures the average squared difference between the observed ($y_i$) and predicted ($\hat{y}_i$) values. It is calculated as:

$$
\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^n (y_i - \hat{y}_i)^2}
$$

Where:

- $y_i$: The actual value of the $i$-th observation.
- $\hat{y}_i$: The predicted value for the $i$-th observation.
- $n$: The total number of observations.

The MAE measures the average absolute difference between the observed ($y_i$) and predicted ($\hat{y}_i$) values. It is calculated as:

$$
\text{MAE} = \frac{1}{n} \sum_{i=1}^n |y_i - \hat{y}_i|
$$

Where:

- $y_i$: The actual value of the $i$-th observation.
- $\hat{y}_i$: The predicted value for the $i$-th observation.
- $n$: The total number of observations.

By comparing the RMSE and MAE results in @tbl-brm, the Linear Model L has slightly lower RMSE and MAE compared to the Bayesian model, suggesting it has a marginally better fit for the given data. As a result, we chose the Linear Model over the Bayesian model.


```{r}
#| label: tbl-brm
#| tbl-cap: Summary of Bayesian Model and Comparison of RMSE / MAE on Test Data
#| tbl-subcap: ['Bayesian Model Shows Similar R2 value Compare to Linear', 'Linear Model shows better fit']
#| echo: false
#| warning: false
#| layout-ncol: 2
modelsummary(brm)

# RMSE and MAE
# GLM
glm_model <- glm_log

# BRM
brm_model <- brm

# GLM predictions (reverse log transformation and convert to Celsius)
glm_predictions_log <- predict(glm_model, newdata = test_data)
glm_predictions_F <- exp(glm_predictions_log)  # Predicted in Fahrenheit
glm_predictions <- (glm_predictions_F - 32) * 5 / 9  # Convert to Celsius

# BRM predictions (posterior predictive mean, reverse log transformation and convert to Celsius)
brm_predictions_log <- colMeans(posterior_predict(brm_model, newdata = test_data))
brm_predictions_F <- exp(brm_predictions_log)  # Predicted in Fahrenheit
brm_predictions <- (brm_predictions_F - 32) * 5 / 9  # Convert to Celsius

# Ensure consistency: Predicted and actual values in Celsius
test_data <- test_data %>%
  mutate(
    actual_mean_temp = mean_temp,      # Actual values (Celsius)
    glm_predicted = glm_predictions,  # GLM predictions (Celsius)
    brm_predicted = brm_predictions   # Bayesian predictions (Celsius)
  )

# Calculate RMSE
rmse_glm <- sqrt(mean((test_data$actual_mean_temp - test_data$glm_predicted)^2))
rmse_brm <- sqrt(mean((test_data$actual_mean_temp - test_data$brm_predicted)^2))

# Calculate MAE
mae_glm <- mean(abs(test_data$actual_mean_temp - test_data$glm_predicted))
mae_brm <- mean(abs(test_data$actual_mean_temp - test_data$brm_predicted))

# Create a data frame for the metrics
metrics <- data.frame(
  Model = c("Linear", "Bayesian"),
  RMSE = c(rmse_glm, rmse_brm),
  MAE = c(mae_glm, mae_brm)
)

# Display the table using kable
kable(metrics) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))

```

## Polynomial Linear Model
Since we choose the Linear Model L over Bayesian Model, we inspect the residual plot of the linear model. The residual plot in @fig-plot-m4p-2 shows a non-linear pattern, as indicated by the curved trend in the residuals. This suggests that the relationship between the predictors and the response variable is not fully captured by a linear model. Adding polynomial terms could help address this non-linearity by allowing the model to fit curved relationships. The detail of the new model is discussed in @sec-model.

\newpage

# Additional Data Details

The summary statistics of the cleaned data are shown in @tbl-summary.

```{r}
#| label: tbl-summary
#| tbl-cap: Summary Statistics of Raw Climate Data 
#| echo: false
#| warning: false
# Generate the table
analysis_data |>
  select(wind_speed, total_precipitation, snow, pressure_station,
  max_temp, min_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Wind Speed", "Total Precipitation", "Snow", "Pres.", 
      "Max Temp", "Min Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(mean_temp, total_rain, gust_speed_km_h,
  mean_temp_F, log_mean_temp) |>
  summary() |>
  kable(
    col.names = c(
      "Mean Temp", "Rain", 
      "Max Gust Speed", "Mean Temp in F", "Log of Mean Temp"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )
analysis_data |>
  select(total_precipitation_boxcox, log_gust_speed, log_wind_speed, log_pressure) |>
  summary() |>
  kable(
    col.names = c(
      "Box Cox of Precipitation", "Log of Gust Speed", "Log of Wind Speed",
      "Log of Pressure"
    ),
    booktabs = TRUE,
    align = "c",  # Center-align all columns
    format = "latex"  # Ensure LaTeX output
  )

```

\newpage

As discussed in @sec-data, the histogram of variables before and after transformation is displayed in @fig-hist-all.
```{r}
#| label: fig-hist-all
#| fig-cap: Other Variables Show Normal Distribution
#| fig-subcap: ['Wind Speed Shows Symmetric Distribution', 'Total Precipitation Shows Normal Distribution but Skewed Towards Low Values', 'Pressure Station Has a Nearly Normal Distribution', 'Gust Speed Shows Normal Distribution and Moderate Skewness', 'Box-Cox Transformed Precipitation shows Reduces Skewness', 'Log Transformed Gust Speed shows Reduces Skewness', 'Log Transformed Pressure shows Reduces Skewness', 'Log Transformed Wind Speed shows Reduces Skewness']
#| echo: false
#| warning: false
#| layout-ncol: 3

df <- analysis_data

# Plot histogram for wind_speed
ggplot(df, aes(x = wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for total_precipitation
ggplot(df, aes(x = total_precipitation)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Total Precipitation", x = "Total Precipitation (mm)", y = "Frequency") +
  theme_minimal()

# Plot histogram for pressure_station
ggplot(df, aes(x = pressure_station)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = gust_speed_km_h)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for gust_speed_km_h
ggplot(df, aes(x = total_precipitation_boxcox)) +
  geom_histogram(fill = "green", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Box-Cox of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

ggplot(df, aes(x = log_gust_speed)) +
  geom_histogram(fill = "red", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Gust Speed", x = "Gust Speed (km/h)", y = "Frequency") +
  theme_minimal()

# Plot histogram for log_pressure
ggplot(df, aes(x = log_pressure)) +
  geom_histogram(fill = "black", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Pressure Station", x = "Pressure (hPa)", y = "Frequency") +
  theme_minimal()

# Plot histogram for wind_speed
ggplot(df, aes(x = log_wind_speed)) +
  geom_histogram(fill = "blue", color = "black", alpha = 0.7) +
  labs(title = "Histogram of Log of Wind Speed", x = "Wind Speed (km/h)", y = "Frequency") +
  theme_minimal()

```


# Methodology of ECCC {#sec-methodology}

The Adjusted and Homogenized Canadian Climate Data (AHCCD) is a collection of climate datasets developed by @environment_and_climate_change_canada_adjusted_2021. These datasets provide long-term, quality-controlled data that have been adjusted to correct for non-climatic influences.  

## Population, Frame, and Sample 

The population of interest in the AHCCD is the entirety of Canada’s climate data, representing diverse geographical regions and climate conditions. The frame of the dataset are the climatological stations maintained by the ECCC that span across the countries in important locations such as airports, and banks of lakes or rivers. These stations record data on climate elements such as temperature, precipitation, surface pressure, and wind speed over extended periods. The sample is the selected stations across Canada, with adjustments applied to address inconsistencies. The datasets cover periods extending back to 1895 for precipitation, while other variables like wind speed and surface pressure start from 1953 or later. The recorded sample consists of monthly, seasonal, and annual data about surface air temperature, precipitation, pressure, and wind speed, according to @environment_and_climate_change_canada_adjusted_2021. 

## Sample Corrections and Adjustments 

The original data for AHCCD are extracted from the National Climate Data Archive of Environment Canada. These data include daily observations, such as maximum and minimum temperatures, precipitation, surface pressure, and wind speed. Observations are quality-controlled and adjusted to correct for biases due to changes in instruments, observation procedures, and other factors.  

Precipitation data adjustments account for wind undercatch, evaporation, and gauge-specific losses. According to @environment_and_climate_change_canada_climate_2021-1, corrections to account for wind undercatch, evaporation, and gauge specific wetting losses were implemented, especially in snowy conditions where snowfall is not fully captured by standard gauges. Corrections are made with the study by Devine and Mekis.  

Surface air temperature adjustments apply Quantile-Matching techniques to remove inhomogeneities. According to @environment_and_climate_change_canada_climate_2021, With Vincent and Wang's third generation homogenized temperature, Quantile-Matching ensures that the temperature data remain consistent across different periods, even when observation practices change. 

Surface pressure and wind speed data undergo adjustments based on metadata and statistical tests for systematic shifts. According to @environment_and_climate_change_canada_climate_2021-2, wind speed is first adjusted with a logarithmic wind profile, then tested for homogeneity using a technique based on regression models. It involves the identification of variation due to changes in anemometer and location change. The pressure data is corrected due to systematic shifts of non-updated station elevation and relocation, as stated by @environment_and_climate_change_canada_climate_2021-3. 

## Sampling Approach and Trade-offs 

According to the published methodology and the webpage by @dunbar_adjusted_2020, they employ a systematic sampling approach by selecting specific climatological stations with long-term, consistent data records. In some cases, observations from neighboring or overlapping stations are merged to extend time series. The AHCCD dataset may also contain missing values, which can vary depending on the variable, station, and time. Additionally, the AHCCD dataset is site-specific, meaning it provides data specific to individual observation stations.  

## Missing Data Handling 

Non-response, such as gaps in the data due to missing records, is managed by employing statistical and physical methods to homogenize the data. For instance, the AHCCD adjusts for shifts detected through historical evidence and metadata analysis. For large amount of missing data, ECCC mark the data as NA in the dataset [@canadian_centre_for_climate_services_adjusted_2022]. 

## Strengths and Weaknesses 

The AHCCD by @dunbar_adjusted_2020 provides long-term, high-quality climate records adjusted for non-climatic factors such as changes in instrumentation, observation procedures, and station relocations, ensuring consistency and reliability for trend analysis in climate change.  

The documentation acknowledges the possibility of missing values, which naturally arise in long-term observational datasets due to factors such as station interruptions, relocation, or equipment malfunctions [@environment_and_climate_change_canada_adjusted_2021]. Moreover, the dataset’s coverage in Arctic regions is limited to the restricted to the mid-1940s to present, as this limitation reflects the historical absence of earlier systematic observations in these remote regions. 

\newpage


# References


